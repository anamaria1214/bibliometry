@article{David2023,
  title = {Education in the Era of Generative Artificial Intelligence (AI): Understanding the Potential Benefits of ChatGPT in Promoting Teaching and Learning},
  author = {David Baidoo-Anu and Leticia Owusu Ansah},
  year = {2023},
  url = {https://www.semanticscholar.org/paper/7b6a8c6d44e0f77bf930484e438d77b7465a69fb},
  abstract = {Since its maiden release into the public domain on November 30, 2022, ChatGPT garnered more than one million subscribers within a week. The generative AI tool ⎼ChatGPT took the world by surprise with it sophisticated capacity to carry out remarkably complex tasks. The extraordinary abilities of ChatGPT to perform complex tasks within the field of education has caused mixed feelings among educators, as this advancement in AI seems to revolutionize existing educational praxis. This is an exploratory study that synthesizes recent extant literature to offer some potential benefits and drawbacks of ChatGPT in promoting teaching and learning. Benefits of ChatGPT include but are not limited to promotion of personalized and interactive learning, generating prompts for formative assessment activities that provide ongoing feedback to inform teaching and learning etc. The paper also highlights some inherent limitations in the ChatGPT such as generating wrong information, biases in data training, which may augment existing biases, privacy issues etc. The study offers recommendations on how ChatGPT could be leveraged to maximize teaching and learning. Policy makers, researchers, educators and technology experts could work together and start conversations on how these evolving generative AI tools could be used safely and constructively to improve education and support students’ learning.},
}

@article{G.2023,
  title = {Examining Science Education in ChatGPT: An Exploratory Study of Generative Artificial Intelligence},
  author = {G. Cooper},
  year = {2023},
  url = {https://www.semanticscholar.org/paper/6f4486c3d8ccd638c2a6bcbfafa01b5a3225bcab},
  abstract = {The advent of generative artificial intelligence (AI) offers transformative potential in the field of education. The study explores three main areas: (1) How did ChatGPT answer questions related to science education? (2) What are some ways educators could utilise ChatGPT in their science pedagogy? and (3) How has ChatGPT been utilised in this study, and what are my reflections about its use as a research tool? This exploratory research applies a self-study methodology to investigate the technology. Impressively, ChatGPT’s output often aligned with key themes in the research. However, as it currently stands, ChatGPT runs the risk of positioning itself as the ultimate epistemic authority, where a single truth is assumed without a proper grounding in evidence or presented with sufficient qualifications. Key ethical concerns associated with AI include its potential environmental impact, issues related to content moderation, and the risk of copyright infringement. It is important for educators to model responsible use of ChatGPT, prioritise critical thinking, and be clear about expectations. ChatGPT is likely to be a useful tool for educators designing science units, rubrics, and quizzes. Educators should critically evaluate any AI-generated resource and adapt it to their specific teaching contexts. ChatGPT was used as a research tool for assistance with editing and to experiment with making the research narrative clearer. The intention of the paper is to act as a catalyst for a broader conversation about the use of generative AI in science education.},
}

@article{Heather2024,
  title = {Student perspectives on the use of generative artificial intelligence technologies in higher education},
  author = {Heather Johnston and Rebecca F. Wells and Elizabeth M. Shanks and Timothy Boey and Bryony N. Parsons},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/3c10800ee7c707bbf5e9fdb371e1451f9d92e26d},
  abstract = {The aim of this project was to understand student perspectives on generative artificial intelligence (GAI) technologies such as Chat generative Pre-Trained Transformer (ChatGPT), in order to inform changes to the University of Liverpool Academic Integrity code of practice. The survey for this study was created by a library student team and vetted through focus groups. A total of 2555 students participated in the survey. Results showed that only 7% of students who responded had not heard of any GAI technologies, whilst over half had used or considered using these for academic purposes. The majority of students (54.1%) were supportive or somewhat supportive of using tools such as Grammarly, but 70.4% were unsupportive or somewhat unsupportive towards students using tools such as ChatGPT to write their whole essay. Students who had higher levels of confidence in their academic writing were less likely to use or consider using them for academic purposes, and were also less likely to be supportive of other students using them. Most students (41.1%) also thought there should be a university wide policy on when these technologies are or are not appropriate to use. The results of this research suggest that students require clear policies on the use of GAI and that these technologies should not be banned from university, but consideration must be made to ensure different groups of students have equal access to the technologies.},
}

@article{M.2024,
  title = {Generative Artificial Intelligence in Education: From Deceptive to Disruptive},
  author = {M. A. Forment and F. García-Peñalvo and J. Camba},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/08ff8980b5135bb6b8da9f0022001aad1d400d15},
  abstract = {Generative Artificial Intelligence (GenAI) has emerged as a promising technology that can create original content, such as text, images, and sound. The use of GenAI in educational settings is becoming increasingly popular and offers a range of opportunities and challenges. This special issue explores the management and integration of GenAI in educational settings, including the ethical considerations, best practices, and opportunities. The potential of GenAI in education is vast. By using algorithms and data, GenAI can create original content that can be used to augment traditional teaching methods, creating a more interactive and personalized learning experience. In addition, GenAI can be utilized as an assessment tool and for providing feedback to students using generated content. For instance, it can be used to create custom quizzes, generate essay prompts, or even grade essays. The use of GenAI as an assessment tool can reduce the workload of teachers and help students receive prompt feedback on their work. Incorporating GenAI in educational settings also poses challenges related to academic integrity. With availability of GenAI models, students can use them to study or complete their homework assignments, which can raise concerns about the authenticity and authorship of the delivered work. Therefore, it is important to ensure that academic standards are maintained, and the originality of the student's work is preserved. This issue highlights the need for implementing ethical practices in the use of GenAI models and ensuring that the technology is used to support and not replace the student's learning experience.},
}

@article{Matthew2024,
  title = {How should we change teaching and assessment in response to increasingly powerful generative Artificial Intelligence? Outcomes of the ChatGPT teacher survey},
  author = {Matthew S. Bower and Jodie Torrington and Jennifer W. M. Lai and P. Petocz and Mark Alfano},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/5d2f65749187c7369072d7ecbe37784295ac5acd},
  abstract = {There has been widespread media commentary about the potential impact of generative Artificial Intelligence (AI) such as ChatGPT on the Education field, but little examination at scale of how educators believe teaching and assessment should change as a result of generative AI. This mixed methods study examines the views of educators (n = 318) from a diverse range of teaching levels, experience levels, discipline areas, and regions about the impact of AI on teaching and assessment, the ways that they believe teaching and assessment should change, and the key motivations for changing their practices. The majority of teachers felt that generative AI would have a major or profound impact on teaching and assessment, though a sizeable minority felt it would have a little or no impact. Teaching level, experience, discipline area, region, and gender all significantly influenced perceived impact of generative AI on teaching and assessment. Higher levels of awareness of generative AI predicted higher perceived impact, pointing to the possibility of an ‘ignorance effect’. Thematic analysis revealed the specific curriculum, pedagogy, and assessment changes that teachers feel are needed as a result of generative AI, which centre around learning with AI, higher-order thinking, ethical values, a focus on learning processes and face-to-face relational learning. Teachers were most motivated to change their teaching and assessment practices to increase the performance expectancy of their students and themselves. We conclude by discussing the implications of these findings in a world with increasingly prevalent AI.},
}

@article{D.2024,
  title = {Using Generative Artificial Intelligence Tools to Explain and Enhance Experiential Learning for Authentic Assessment},
  author = {D. Salinas-Navarro and E. Vilalta-Perdomo and Rosario Michel-Villarreal and L. Montesinos},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/b71fb682b835500ba19e654584a05c4bb6e65c10},
  abstract = {The emergence of generative artificial intelligence (GenAI) requires innovative educational environments to leverage this technology effectively to address concerns like academic integrity, plagiarism, and others. Additionally, higher education needs effective pedagogies to achieve intended learning outcomes. This emphasizes the need to redesign active learning experiences in the GenAI era. Authentic assessment and experiential learning are two possible meaningful alternatives in this context. Accordingly, this article investigates how GenAI can enhance teaching and learning by constructively addressing study situations beyond conventional learning approaches and cultivating high-order skills and knowledge acquisition. This study employs thing ethnography to examine GenAI tools’ integration with authentic assessment and experiential learning and explore implementation alternatives. The results reveal insights into creating human-centered and GenAI-enhanced learning experiences within a constructive alignment. Specific examples are also provided to guide their implementation. Our contributions extend beyond the traditional use of GenAI tools as mere agents-to-write or agents-to-answer questions to become agents-to-support experiential learning for authentic assessment. These findings underscore the transformative role of GenAI tools in enhancing teaching and learning efficacy and effectiveness. The limitations in treating GenAI tools as subjects in thing ethnography are acknowledged, with potential for future implementation evaluation.},
}

@article{Shakked2023,
  title = {Experimental evidence on the productivity effects of generative artificial intelligence},
  author = {Shakked Noy and Whitney Zhang},
  year = {2023},
  url = {https://www.semanticscholar.org/paper/8d020275181c69e5e768c6ffc40e09710a6f54f1},
  abstract = {We examined the productivity effects of a generative artificial intelligence (AI) technology, the assistive chatbot ChatGPT, in the context of midlevel professional writing tasks. In a preregistered online experiment, we assigned occupation-specific, incentivized writing tasks to 453 college-educated professionals and randomly exposed half of them to ChatGPT. Our results show that ChatGPT substantially raised productivity: The average time taken decreased by 40% and output quality rose by 18%. Inequality between workers decreased, and concern and excitement about AI temporarily rose. Workers exposed to ChatGPT during the experiment were 2 times as likely to report using it in their real job 2 weeks after the experiment and 1.6 times as likely 2 months after the experiment. Description Editor’s summary Automation has historically displaced human workers in factories (e.g., automotive manufacturing) or in performing routine computational tasks. Will generative artificial intelligence (AI) tools such as ChatGPT disrupt the labor market by making educated professionals obsolete, or will these tools complement their skills and enhance productivity? Noy and Zhang examined this issue in an experiment that recruited college-educated professionals to complete incentivized writing tasks. Participants assigned to use ChatGPT were more productive, efficient, and enjoyed the tasks more. Participants with weaker skills benefited the most from ChatGPT, which carries policy implications for efforts to reduce productivity inequality through AI. —EEU The assistive chatbot ChatGPT raises productivity in professional writing tasks and reduces productivity inequality.},
}

@article{J.2023,
  title = {Collaborating With ChatGPT: Considering the Implications of Generative Artificial Intelligence for Journalism and Media Education},
  author = {J. Pavlik},
  year = {2023},
  url = {https://www.semanticscholar.org/paper/9dafa6c5c609348b46734fc8997b93b3587fec6e},
  abstract = {Generative artificial intelligence (AI) is ushering in an era of potential transformation of journalism and media content. This essay considers one notable generative AI platform called ChatGPT made available to the public in 2022 for free use. ChatGPT allows users to enter text prompts and rapidly generates text responses drawn from its knowledge acquired via machine learning in engagement with the internet. This essay is coauthored by a human journalism and media professor in collaboration with ChatGPT. The essay demonstrates the capacity and limitations of ChatGPT and offers reflections on the implications of generative AI for journalism and media education.},
}

@article{M.2024,
  title = {Developing evaluative judgement for a time of generative artificial intelligence},
  author = {M. Bearman and Joanna Tai and P. Dawson and D. Boud and R. Ajjawi},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/5bea14c265e81127f282298ee1274f2b8c2de160},
  abstract = {Abstract Generative artificial intelligence (AI) has rapidly increased capacity for producing textual, visual and auditory outputs, yet there are ongoing concerns regarding the quality of those outputs. There is an urgent need to develop students’ evaluative judgement – the capability to judge the quality of work of self and others – in recognition of this new reality. In this conceptual paper, we describe the intersection between evaluative judgement and generative AI with a view to articulating how assessment practices can help students learn to work productively with generative AI. We propose three foci: (1) developing evaluative judgement of generative AI outputs; (2) developing evaluative judgement of generative AI processes; and (3) generative AI assessment of student evaluative judgements. We argue for developing students’ capabilities to identify and calibrate quality of work – uniquely human capabilities at a time of technological acceleration – through existing formative assessment strategies. These approaches circumvent and interrupt students’ uncritical usage of generative AI. The relationship between evaluative judgement and generative AI is more than just the application of human judgement to machine outputs. We have a collective responsibility, as educators and learners, to ensure that humans do not relinquish their roles as arbiters of quality.},
}

@article{Siu-Cheung2024,
  title = {A Human-Centered Learning and Teaching Framework Using Generative Artificial Intelligence for Self-Regulated Learning Development Through Domain Knowledge Learning in K–12 Settings},
  author = {Siu-Cheung Kong and Yin Yang},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/f710896031d29efc4aaa2abe302db3c6f8332248},
  abstract = {The advent of generative artificial intelligence (AI) has ignited an increase in discussions about generative AI tools in education. In this study, a human-centered learning and teaching framework that uses generative AI tools for self-regulated learning development through domain knowledge learning was proposed to catalyze changes in educational practices. The framework illustrates how generative AI tools can revolutionize educational practices and transform the processes of teaching and learning to become human-centered. It emphasizes the evolving roles of teachers, who increasingly become skillful facilitators and humanistic storytellers who craft differentiated instructions and attempt to develop students’ individualized learning. Drawing upon insights from neuroscience, the framework guides students to employ generative AI tools to augment their attentiveness, stimulate active engagement in learning, receive immediate feedback, and encourage self-reflection. The pedagogical approach is also reimagined; teachers equipped with generative AI tools and AI literacy can refine their teaching strategies to better equip students to meet future challenges. The practical application of the framework is demonstrated in a case study involving the development of Chinese language writing ability among primary students within a K–12 educational context. This article also reports the results of a 60-h development programme for teachers. Specifically, providing in-service teachers with cases involving uses of the proposed framework helped them to better understand the generative AI concepts and integrate them into their teaching and learning and increased their perceived ability to design AI-integrated courses that would enhance students’ attention, engagement, confidence, and satisfaction.},
}

@article{Hind2024,
  title = {Navigating Generative Artificial Intelligence Promises and Perils for Knowledge and Creative Work},
  author = {Hind Benbya and Franz Strich and Toomas Tamm},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/8694bb2b5a2bb0cc88121160280e071fe34f94e6},
  abstract = {Generative artificial intelligence (GenAI) is rapidly becoming a viable tool to enhance productivity and act as a catalyst for innovation across various sectors. Its ability to perform tasks that have traditionally required human judgment and creativity is transforming knowledge and creative work. Yet it also raises concerns and implications that could reshape the very landscape of knowledge and creative work. In this editorial, we undertake an in-depth examination of both the opportunities and challenges presented by GenAI for future IS research.},
}

@article{Humaid2024,
  title = {Enhancing Work Productivity through Generative Artificial Intelligence: A Comprehensive Literature Review},
  author = {Humaid Al Naqbi and Zied Bahroun and Vian Ahmed},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/cc4a3422e011ca4715403f3bd818d37dc32d9d84},
  abstract = {In this review, utilizing the PRISMA methodology, a comprehensive analysis of the use of Generative Artificial Intelligence (GAI) across diverse professional sectors is presented, drawing from 159 selected research publications. This study provides an insightful overview of the impact of GAI on enhancing institutional performance and work productivity, with a specific focus on sectors including academia, research, technology, communications, agriculture, government, and business. It highlights the critical role of GAI in navigating AI challenges, ethical considerations, and the importance of analytical thinking in these domains. The research conducts a detailed content analysis, uncovering significant trends and gaps in current GAI applications and projecting future prospects. A key aspect of this study is the bibliometric analysis, which identifies dominant tools like Chatbots and Conversational Agents, notably ChatGPT, as central to GAI’s evolution. The findings indicate a robust and accelerating trend in GAI research, expected to continue through 2024 and beyond. Additionally, this study points to potential future research directions, emphasizing the need for improved GAI design and strategic long-term planning, particularly in assessing its impact on user experience across various professional fields.},
}

@article{Lixiang2024,
  title = {Promises and challenges of generative artificial intelligence for human learning},
  author = {Lixiang Yan and Samuel Greiff and Ziwen Teuber and D. Gašević},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/90a3410bc1632ba3340de7259186c66ba03f1668},
  abstract = {Generative artificial intelligence (GenAI) holds the potential to transform the delivery, cultivation and evaluation of human learning. Here the authors examine the integration of GenAI as a tool for human learning, addressing its promises and challenges from a holistic viewpoint that integrates insights from learning sciences, educational technology and human-computer interaction. GenAI promises to enhance learning experiences by scaling personalized support, diversifying learning materials, enabling timely feedback and innovating assessment methods. However, it also presents critical issues such as model imperfections, ethical dilemmas and the disruption of traditional assessments. Thus, cultivating AI literacy and adaptive skills is imperative for facilitating informed engagement with GenAI technologies. Rigorous research across learning contexts is essential to evaluate GenAI's effect on human cognition, metacognition and creativity. Humanity must learn with and about GenAI, ensuring that it becomes a powerful ally in the pursuit of knowledge and innovation, rather than a crutch that undermines our intellectual abilities.},
}

@article{Chengliang2024,
  title = {Factors Influencing University Students’ Behavioral Intention to Use Generative Artificial Intelligence: Integrating the Theory of Planned Behavior and AI Literacy},
  author = {Chengliang Wang and Haoming Wang and Yuanyuan Li and Jian Dai and Xiaoqing Gu and Teng Yu},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/71353200a4f9757e10d0243e231fc5bcd14d8387},
  abstract = {Abstract Generative artificial intelligence (GAI) advancements have ignited new expectations for artificial intelligence (AI)-enabled educational transformations. Based on the theory of planned behavior (TPB), this study combines structural equation modeling and interviews to analyze the influencing factors of Chinese university students’ GAI technology usage intention. Regarding AI literacy, students’ cognitive literacy in AI ethics scored the highest (M = 5.740), while AI awareness literacy scored the lowest (M = 4.578). Students’ attitudes toward GAI significantly and positively influenced their usage intention, with the combined TPB framework and AI literacy explaining 59.3% of the variance. AI literacy and subjective norms positively influenced students’ attitudes toward GAI technology and perceived behavioral control, and attitude mediated the impact of AI literacy and subjective norms on GAI usage intention. Further, the interviews provide new insights for university management and educational leadership regarding the construction of an educational ecosystem under the application of GAI technology.},
}

@article{Conner2024,
  title = {Publishers’ and journals’ instructions to authors on use of generative artificial intelligence in academic and scientific publishing: bibliometric analysis},
  author = {Conner Ganjavi and M. Eppler and Asli Pekcan and Brett Biedermann and Andre Abreu and Gary S. Collins and I. Gill and Giovanni E. Cacciamani},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/676b1c74535efca92fbb79a26ea66df9ea07e7e7},
  abstract = {Abstract Objectives To determine the extent and content of academic publishers’ and scientific journals’ guidance for authors on the use of generative artificial intelligence (GAI). Design Cross sectional, bibliometric study. Setting Websites of academic publishers and scientific journals, screened on 19-20 May 2023, with the search updated on 8-9 October 2023. Participants Top 100 largest academic publishers and top 100 highly ranked scientific journals, regardless of subject, language, or country of origin. Publishers were identified by the total number of journals in their portfolio, and journals were identified through the Scimago journal rank using the Hirsch index (H index) as an indicator of journal productivity and impact. Main outcome measures The primary outcomes were the content of GAI guidelines listed on the websites of the top 100 academic publishers and scientific journals, and the consistency of guidance between the publishers and their affiliated journals. Results Among the top 100 largest publishers, 24% provided guidance on the use of GAI, of which 15 (63%) were among the top 25 publishers. Among the top 100 highly ranked journals, 87% provided guidance on GAI. Of the publishers and journals with guidelines, the inclusion of GAI as an author was prohibited in 96% and 98%, respectively. Only one journal (1%) explicitly prohibited the use of GAI in the generation of a manuscript, and two (8%) publishers and 19 (22%) journals indicated that their guidelines exclusively applied to the writing process. When disclosing the use of GAI, 75% of publishers and 43% of journals included specific disclosure criteria. Where to disclose the use of GAI varied, including in the methods or acknowledgments, in the cover letter, or in a new section. Variability was also found in how to access GAI guidelines shared between journals and publishers. GAI guidelines in 12 journals directly conflicted with those developed by the publishers. The guidelines developed by top medical journals were broadly similar to those of academic journals. Conclusions Guidelines by some top publishers and journals on the use of GAI by authors are lacking. Among those that provided guidelines, the allowable uses of GAI and how it should be disclosed varied substantially, with this heterogeneity persisting in some instances among affiliated publishers and journals. Lack of standardization places a burden on authors and could limit the effectiveness of the regulations. As GAI continues to grow in popularity, standardized guidelines to protect the integrity of scientific output are needed.},
}

@article{Yizhou2024,
  title = {Beware of Metacognitive Laziness: Effects of Generative Artificial Intelligence on Learning Motivation, Processes, and Performance},
  author = {Yizhou Fan and Luzhen Tang and Huixiao Le and Kejie Shen and Shufang Tan and Yueying Zhao and Yuan Shen and Xinyu Li and D. Gašević},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/97a5fb3512be8dfd9c8a32f4c556ad9db6030288},
  abstract = {With the continuous development of technological and educational innovation, learners nowadays can obtain a variety of supports from agents such as teachers, peers, education technologies, and recently, generative artificial intelligence such as ChatGPT. In particular, there has been a surge of academic interest in human‐AI collaboration and hybrid intelligence in learning. The concept of hybrid intelligence is still at a nascent stage, and how learners can benefit from a symbiotic relationship with various agents such as AI, human experts and intelligent learning systems is still unknown. The emerging concept of hybrid intelligence also lacks deep insights and understanding of the mechanisms and consequences of hybrid human‐AI learning based on strong empirical research. In order to address this gap, we conducted a randomised experimental study and compared learners' motivations, self‐regulated learning processes and learning performances on a writing task among different groups who had support from different agents, that is, ChatGPT (also referred to as the AI group), chat with a human expert, writing analytics tools, and no extra tool. A total of 117 university students were recruited, and their multi‐channel learning, performance and motivation data were collected and analysed. The results revealed that: (1) learners who received different learning support showed no difference in post‐task intrinsic motivation; (2) there were significant differences in the frequency and sequences of the self‐regulated learning processes among groups; (3) ChatGPT group outperformed in the essay score improvement but their knowledge gain and transfer were not significantly different. Our research found that in the absence of differences in motivation, learners with different supports still exhibited different self‐regulated learning processes, ultimately leading to differentiated performance. What is particularly noteworthy is that AI technologies such as ChatGPT may promote learners' dependence on technology and potentially trigger “metacognitive laziness”. In conclusion, understanding and leveraging the respective strengths and weaknesses of different agents in learning is critical in the field of future hybrid intelligence.
What is already known about this topic

Hybrid intelligence, combining human and machine intelligence, aims to augment human capabilities rather than replace them, creating opportunities for more effective lifelong learning and collaboration.
Generative AI, such as ChatGPT, has shown potential in enhancing learning by providing immediate feedback, overcoming language barriers and facilitating personalised educational experiences.
The effectiveness of AI in educational contexts varies, with some studies highlighting its benefits in improving academic performance and motivation, while others note limitations in its ability to replace human teachers entirely.
What this paper adds

We conducted a randomised experimental study in the lab setting and compared learners' motivations, self‐regulated learning processes and learning performances among different agent groups (AI, human expert and checklist tools).
We found that AI technologies such as ChatGPT may promote learners' dependence on technology and potentially trigger metacognitive "laziness", which can potentially hinder their ability to self‐regulate and engage deeply in learning.
We also found that ChatGPT can significantly improve short‐term task performance, but it may not boost intrinsic motivation and knowledge gain and transfer.
Implications for practice and/or policy

When using AI in learning, learners should focus on deepening their understanding of knowledge and actively engage in metacognitive processes such as evaluation, monitoring, and orientation, rather than blindly following ChatGPT's feedback solely to complete tasks efficiently.
When using AI in teaching, teachers should think about which tasks are suitable for learners to complete with the assistance of AI, pay attention to stimulating learners' intrinsic motivations, and develop scaffolding to assist learners in active learning.
Researcher should design multi‐task and cross‐context studies in the future to deepen our understanding of how learners could ethically and effectively learn, regulate, collaborate and evolve with AI.

},
}

@article{Qi2024,
  title = {A scoping review on how generative artificial intelligence transforms assessment in higher education},
  author = {Qi Xia and Xiaojing Weng and Ouyang Fan and Tzung-Jin Lin and T. Chiu},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/de0ee1e7970e9ffff4add57f1fe72623453dae19},
  abstract = {Generative artificial intelligence provides both opportunities and challenges for higher education. Existing literature has not properly investigated how this technology would impact assessment in higher education. This scoping review took a forward-thinking approach to investigate how generative artificial intelligence transforms assessment in higher education. We used the PRISMA extension for scoping reviews to select articles for review and report the results. In the screening, we retrieved 969 articles and selected 32 empirical studies for analysis. Most of the articles were published in 2023. We used three levels—students, teachers, and institutions—to analyses the articles. Our results suggested that assessment should be transformed to cultivate students’ self-regulated learning skills, responsible learning, and integrity. To successfully transform assessment in higher education, the review suggested that (i) teacher professional development activities for assessment, AI, and digital literacy should be provided, (ii) teachers’ beliefs about human and AI assessment should be strengthened, and (iii) teachers should be innovative and holistic in their teaching to reflect the assessment transformation. Educational institutions are recommended to review and rethink their assessment policies, as well as provide more inter-disciplinary programs and teaching.},
}

@article{Lena2024,
  title = {Collaborative Working and Critical Thinking: Adoption of Generative Artificial Intelligence Tools in Higher Education},
  author = {Lena Ivannova Ruiz-Rojas and Luis Salvador-Ullauri and Patricia Acosta-Vargas},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/4e9fefd759c0d0f920533cd70676a59e291729e2},
  abstract = {This study explores the impact of generative artificial intelligence tools on critical thinking and collaboration among university students, highlighting the importance of investigating these technologies due to their increasing integration into higher education and their potential to transform traditional pedagogical practices. A predominantly female sample was surveyed to assess their familiarity with and experience and perceptions of these tools. A total of 87% of the respondents had prior knowledge of generative AI tools, with 38% using them occasionally. Among the most popular tools are Canva 2024 (33%), Chat PDF (26%), and YOU.COM (24%). Additionally, 64% of the respondents believe that these tools significantly improve their critical thinking ability. Despite their high familiarity with and occasional use of these tools, the need for continuous training and technical support was identified. While generative AI tools show promising potential for enhancing collaboration and critical thinking in higher education, previous research has limitations, such as the lack of longitudinal data and the inadequacy in addressing ethical considerations and potential biases. More comprehensive research is needed to understand their long-term impact better and maximize their potential benefits.},
}

@article{Xiang2024,
  title = {The Short-Term Effects of Generative Artificial Intelligence on Employment: Evidence from an Online Labor Market},
  author = {Xiang Hui and O. Reshef and Luofeng Zhou},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/47bef342b9e1204a1360ef087556bd1243c65e59},
  abstract = {Generative artificial intelligence (AI) holds the potential to either complement workers by enhancing their productivity or substitute them. We examine the short-term effects of the recently released generative AI models (ChatGPT, DALL-E 2, and Midjourney) on the employment outcomes of freelancers on a large online platform. We find that freelancers in highly affected occupations suffer from the introduction of generative AI, experiencing reductions in both employment and earnings. We find similar effects studying the release of other image-based generative AI models. Exploring the heterogeneity by freelancers’ employment history, we do not find evidence that high-quality service, measured by their past performance and employment, moderates the adverse effects on employment. In fact, we find suggestive evidence that top freelancers are disproportionately affected by AI. These results suggest that generative AI may transform the role of human capital in the organization and reduce overall demand for workers. Supplemental Material: The online appendices are available at https://doi.org/10.1287/orsc.2023.18441 .},
}

@article{Almog2024,
  title = {The persuasive effects of political microtargeting in the age of generative artificial intelligence},
  author = {Almog Simchon and Matthew Edwards and Stephan Lewandowsky},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/46694f750ff97513e48b5eb8b52c2184d5840b2b},
  abstract = {Abstract The increasing availability of microtargeted advertising and the accessibility of generative artificial intelligence (AI) tools, such as ChatGPT, have raised concerns about the potential misuse of large language models in scaling microtargeting efforts for political purposes. Recent technological advancements, involving generative AI and personality inference from consumed text, can potentially create a highly scalable “manipulation machine” that targets individuals based on their unique vulnerabilities without requiring human input. This paper presents four studies examining the effectiveness of this putative “manipulation machine.” The results demonstrate that personalized political ads tailored to individuals’ personalities are more effective than nonpersonalized ads (studies 1a and 1b). Additionally, we showcase the feasibility of automatically generating and validating these personalized ads on a large scale (studies 2a and 2b). These findings highlight the potential risks of utilizing AI and microtargeting to craft political messages that resonate with individuals based on their personality traits. This should be an area of concern to ethicists and policy makers.},
}

@article{Ilya2024,
  title = {Generative artificial intelligence in supply chain and operations management: a capability-based framework for analysis and implementation},
  author = {Ilya Jackson and Dmitry A. Ivanov and Alexandre Dolgui and Jafar Namdar},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/14faed00db373d87bf90e8ee8f2c0dbbeed768dd},
  abstract = {This research examines the transformative potential of artificial intelligence (AI) in general and Generative AI (GAI) in particular in supply chain and operations management (SCOM). Through the lens of the resource-based view and based on key AI capabilities such as learning, perception, prediction, interaction, adaptation, and reasoning, we explore how AI and GAI can impact 13 distinct SCOM decision-making areas. These areas include but are not limited to demand forecasting, inventory management, supply chain design, and risk management. With its outcomes, this study provides a comprehensive understanding of AI and GAI's functionality and applications in the SCOM context, offering a practical framework for both practitioners and researchers. The proposed framework systematically identifies where and how AI and GAI can be applied in SCOM, focussing on decision-making enhancement, process optimisation, investment prioritisation, and skills development. Managers can use it as a guidance to evaluate their operational processes and identify areas where AI and GAI can deliver improved efficiency, accuracy, resilience, and overall effectiveness. The research underscores that AI and GAI, with their multifaceted capabilities and applications, open a revolutionary potential and substantial implications for future SCOM practices, innovations, and research.},
}

@article{Mohammad2024,
  title = {Higher Education Students' Task Motivation in the Generative Artificial Intelligence Context: The Case of ChatGPT},
  author = {Mohammad Hmoud and Hadeel Swaity and Nardin Hamad and Omar Karram and Wajeeh M. Daher},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/63dcc16b918c6fced2b10e721a8c4bf09d5582be},
  abstract = {Artificial intelligence has been attracting the attention of educational researchers recently, especially ChatGPT as a generative artificial intelligence tool. The context of generative artificial intelligence could impact different aspects of students’ learning, such as the motivational aspect. The present research intended to investigate the characteristics of students’ task motivation in the artificial intelligence context, specifically in the ChatGPT context. The researchers interviewed 15 students about their experiences with ChatGPT to collect data. The researchers used inductive and deductive content analysis to investigate students’ motivation when learning with ChatGPT. To arrive at the categories and sub-categories of students’ motivation, the researchers used the MAXQDA 2022. Five main categories emerged: task enjoyment, reported effort, result assessment, perceived relevance, and interaction. Each category comprised at least two sub-categories, and each sub-category was further organized into codes. The results indicated more positive characteristics of motivation than negative ones. The previous results could be due to the conversational or social aspect of the chatbot, enabling relationships with humans and enabling the maintenance of good quality conversations with them. We conclude that a generative AI could be utilized in educational settings to promote students’ motivation to learn and thus raise their learning achievement.},
}

@article{Maryam2024,
  title = {Knowledge Management Perspective of Generative Artificial Intelligence},
  author = {Maryam Alavi and D. Leidner and Reza Mousavi},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/d7a8a9229a3a4d41be63ecfbbacd825bccb30d09},
  abstract = {In this editorial, revisiting Alavi and Leidner (2001) as a conceptual lens, we consider the organizational implications of Generative Artificial Intelligence (GenAI) from a knowledge management (KM) perspective. We examine how GenAI impact the processes of knowledge creation, storage, transfer, and application, highlighting both the opportunities and challenges this technology presents. In knowledge creation, GenAI enhances information? processing and cognitive functions, fostering individual and organizational learning. However, it also introduces risks like AI bias and reduced human socialization, potentially marginalizing junior knowledge workers. For knowledge storage and retrieval, GenAI’s ability to quickly access vast knowledge bases significantly changes employee interactions with KM systems. This raises questions about balancing human-derived tacit knowledge with AI-generated explicit knowledge. The paper also explores GenAI’s role in knowledge transfer, particularly in training and cultivating a learning culture. Challenges include an over-reliance on AI and risks in disseminating sensitive information. In terms of knowledge application, GenAI is seen as a tool to boost productivity and innovation, but issues like knowledge misapplication, intellectual property, and ethical considerations are critical. Conclusively, the paper argues for a balanced approach to integrating GenAI into KM processes. It advocates for harmonizing GenAI’s capabilities with human insights to effectively manage knowledge in contemporary organizations, ensuring both technological advances and ethical responsibility.},
}

@article{Timothy2024,
  title = {Inadequacies of Large Language Model Benchmarks in the Era of Generative Artificial Intelligence},
  author = {Timothy R. Mcintosh and Teo Sušnjak and Tong Liu and Paul A. Watters and Malka N. Halgamuge},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/068ff3def994d1424832e1f56ed72ef8245a42f0},
  abstract = {The rapid rise in popularity of Large Language Models (LLMs) with emerging capabilities has spurred public curiosity to evaluate and compare different LLMs, leading many researchers to propose their own LLM benchmarks. Noticing preliminary inadequacies in those benchmarks, we embarked on a study to critically assess 23 state-of-the-art LLM benchmarks, using our novel unified evaluation framework through the lenses of people, process, and technology, under the pillars of benchmark functionality and integrity. Our research uncovered significant limitations, including biases, difficulties in measuring genuine reasoning, adaptability, implementation inconsistencies, prompt engineering complexity, evaluator diversity, and the overlooking of cultural and ideological norms in one comprehensive assessment. Our discussions emphasized the urgent need for standardized methodologies, regulatory certainties, and ethical guidelines in light of Artificial Intelligence (AI) advancements, including advocating for an evolution from static benchmarks to dynamic behavioral profiling to accurately capture LLMs' complex behaviors and potential risks. Our study highlighted the necessity for a paradigm shift in LLM evaluation methodologies, underlining the importance of collaborative efforts for the development of universally accepted benchmarks and the enhancement of AI systems' integration into society.},
}

@article{Faisal2024,
  title = {A Primer on Generative Artificial Intelligence},
  author = {Faisal Kalota},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/ed90ca3acf39066225e9f8e1d6d5b5de2a878361},
  abstract = {Many educators and professionals in different industries may need to become more familiar with the basic concepts of artificial intelligence (AI) and generative artificial intelligence (Gen-AI). Therefore, this paper aims to introduce some of the basic concepts of AI and Gen-AI. The approach of this explanatory paper is first to introduce some of the underlying concepts, such as artificial intelligence, machine learning, deep learning, artificial neural networks, and large language models (LLMs), that would allow the reader to better understand generative AI. The paper also discusses some of the applications and implications of generative AI on businesses and education, followed by the current challenges associated with generative AI.},
}

@article{Siqin2024,
  title = {GPT, large language models (LLMs) and generative artificial intelligence (GAI) models in geospatial science: a systematic review},
  author = {Siqin Wang and Tao Hu and Huang Xiao and Yun Li and Ce Zhang and H. Ning and Rui Zhu and Z. Li and Xinyue Ye},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/2d30e8e8ea25803f1ae0fb1ca97c1e48bb3c32fa},
  abstract = {ABSTRACT The launch of large language models (LLMs) like ChatGPT in late 2022 and the anticipated arrival of future GPT-x iterations have marked the beginning of the generative artificial intelligence (GAI) era. We conducted a systematic review of how to integrate LLMs including GPT and other GAI models into geospatial science, based on 293 papers obtained from four databases of academic publications – Web of Science (WoS), Scopus, SSRN and arXiv – 26 papers were eventually included for analysis. We statistically outlined the share of domains where LLMs and other GAI models, the type of data that have been used for these models, and the modelling tasks and roles that they play. We also pointed out the challenges and future directions for the next research agenda – along with which we could better position ourselves in the mainstream of science and the cutting-edge research paradigm as others leverage insights from the growing data deluge.},
}

@article{Amir2024,
  title = {Unlocking de novo antibody design with generative artificial intelligence},
  author = {Amir Shanehsazzadeh and S. Bachas and George Kasun and J. Sutton and A. Steiger and Richard W. Shuai and Christa Kohnert and Alex Morehead and Amber Brown and Chelsea Chung and Breanna K. Luton and Nicolas Diaz and Matt McPartlon and Bailey Knight and Macey Radach and K. Bateman and David A. Spencer and Jovan Cejovic and Gaelin Kopec-Belliveau and Robel Haile and Edriss Yassine and Cailen M. McCloskey and Monica Natividad and Dalton Chapman and Luka Stojanovic and G. Rakocevic and G. Hannum and Engin Yapici and Katherine M. Moran and Rodante Caguiat and S. Abdulhaqq and Zheyuan Guo and Lillian R. Klug and Miles Gander and Joshua Meier},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/adfcc00814fbb55a4b0c430c5c004bf7988734cb},
  abstract = {Generative AI has the potential to redefine the process of therapeutic antibody discovery. In this report, we describe and validate deep generative models for the de novo design of antibodies against human epidermal growth factor receptor (HER2) without additional optimization. The models enabled an efficient workflow that combined in silico design methods with high-throughput experimental techniques to rapidly identify binders from a library of ∼106 heavy chain complementarity-determining region (HCDR) variants. We demonstrated that the workflow achieves binding rates of 10.6% for HCDR3 and 1.8% for HCDR123 designs and is statistically superior to baselines. We further characterized 421 diverse binders using surface plasmon resonance (SPR), finding 71 with low nanomolar affinity similar to the therapeutic anti-HER2 antibody trastuzumab. A selected subset of 11 diverse high-affinity binders were functionally equivalent or superior to trastuzumab, with most demonstrating suitable developability features. We designed one binder with ∼3x higher cell-based potency compared to trastuzumab and another with improved cross-species reactivity1. Our generative AI approach unlocks an accelerated path to designing therapeutic antibodies against diverse targets.},
}

@article{C.2024,
  title = {Generative artificial intelligence in primary care: an online survey of UK general practitioners},
  author = {C. Blease and Cosima Locher and Jens Gaab and M. Hägglund and K. Mandl},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/7d7f20d8822e4dd444fb5788c1fa354a3f2a0401},
  abstract = {Objectives Following the launch of ChatGPT in November 2022, interest in large language model-powered chatbots has soared with increasing focus on the clinical potential of these tools. We sought to measure general practitioners’ (GPs) current use of this new generation of chatbots to assist with any aspect of clinical practice in the UK. Methods An online survey was distributed to a non-probability sample of GPs registered with the clinician marketing service Doctors.net.uk. The study was launched as a monthly ‘omnibus survey’ which has a predetermined sample size of 1000 participants. Results 531 (53%) respondents were men, 544 (54%) were 46 years or older. 20% (205) reported using generative artificial intelligence (AI) tools in clinical practice; of those who answered affirmatively and were invited to clarify further, 29% (47) reported using these tools to generate documentation after patient appointments and 28% (45) to suggest a differential diagnosis. Discussion Administered a year after ChatGPT was launched, this is the largest survey we know of conducted into doctors’ use of generative AI in clinical practice. Findings suggest that GPs may derive value from these tools, particularly with administrative tasks and to support clinical reasoning. Conclusion Despite a lack of guidance about these tools and unclear work policies, GPs report using generative AI to assist with their job. The medical community will need to find ways to both educate physicians and trainees and guide patients about the safe adoption of these tools.},
}

@article{R.2024,
  title = {The Societal Impacts of Generative Artificial Intelligence: A Balanced Perspective},
  author = {R. Sabherwal and Varun Grover},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/67756c32f468f21f0b3668ba20ed031e2c8fc9e5},
  abstract = {The discourse surrounding the societal impacts of generative artificial intelligence (GAI), exemplified
by technologies like ChatGPT, often oscillates between extremes: utopian visions of unprecedented
productivity and dystopian fears of humanity’s demise. This polarized perspective neglects the
nuanced, pragmatic manifestation of GAI. In general, extreme views oversimplify the technology itself
or its potential to address societal issues. The authors suggest a more balanced analysis, acknowledging
that GAI’s impacts will unfold dynamically over time as diverse implementations interact with human
stakeholders and contextual factors. While Big Tech firms dominate GAI’s supply, its demand is
expected to evolve through experimentation and use cases. The authors argue that GAI’s societal impact
depends on identifiable contingencies, emphasizing three broad factors: the balance between
automation and augmentation, the congruence of physical and digital realities, and the retention of
human bounded rationality. These contingencies represent trade-offs arising from GAI instantiations,
shaped by technological advancements, stakeholder dynamics, and contextual factors, including
societal responses and regulations. Predicting long-term societal effects remains challenging due to
unforeseeable discontinuities in the technology’s trajectory. The authors anticipate a continuous
interplay between GAI initiatives, technological advances, learning experiences, and societal
responses, with outcomes depending on the above contingencies.},
}

@article{A.2024,
  title = {A Comparative Analysis of Generative Artificial Intelligence Tools for Natural Language Processing},
  author = {A. Iorliam and Joseph Abunimye Ingio},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/aaa971c619766f9445c223a22783dab303b7d526},
  abstract = {Generative artificial intelligence tools have recently attracted a great deal of attention. This is because of their huge advantages, which include ease of usage, quick generation of answers to requests, and the human-like intelligence they possess. This paper presents a vivid comparative analysis of the top 9 generative artificial intelligence (AI) tools, namely ChatGPT, Perplexity AI, YouChat, ChatSonic, Google's Bard, Microsoft Bing Assistant, HuggingChat, Jasper AI, and Quora's Poe, paying attention to the Pros and Cons each of the AI tools presents. This comparative analysis shows that the generative AI tools have several Pros that outweigh the Cons. Further, we explore the transformative impact of generative AI in Natural Language Processing (NLP), focusing on its integration with search engines, privacy concerns, and ethical implications. A comparative analysis categorizes generative AI tools based on popularity and evaluates challenges in development, including data limitations and computational costs. The study highlights ethical considerations such as technology misuse and regulatory challenges. Additionally, we delved into AI Planning techniques in NLP, covering classical planning, probabilistic planning, hierarchical planning, temporal planning, knowledge-driven planning, and neural planning models. These planning approaches are vital in achieving specific goals in NLP tasks. In conclusion, we provide a concise overview of the current state of generative AI, including its challenges, ethical considerations, and potential applications, contributing to the academic discourse on human-computer interaction.  },
}

@article{Varun2024,
  title = {An Empirical Evaluation of a Generative Artificial Intelligence Technology Adoption Model from Entrepreneurs' Perspectives},
  author = {Varun Gupta},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/106cdc3f272e61d73a944aae9a4497ef67d0c6e1},
  abstract = {Technologies, such as Chat Generative Pre-Trained Transformer (ChatGPT, Smart PLS version 4), are prime examples of Generative Artificial Intelligence (AI), which is a constantly evolving area. SMEs, particularly startups, can obtain a competitive edge, innovate their business models, gain business value, and undergo a digital transformation by implementing these technologies. Continuous but gradual experimentation with these technologies is the foundation for their adoption. The experience that comes from trying new technologies can help entrepreneurs adopt new technologies more strategically and experiment more with them. The urgent need for an in-depth investigation is highlighted by the paucity of previous research on ChatGPT uptake in the startup context, particularly from an entrepreneurial perspective. The objective of this research study is to empirically validate the Generative AI technology adoption model to establish the direction and strength of the correlations among the adoption factors from the perspectives of the entrepreneurs. The data are collected from 482 entrepreneurs who exhibit great diversity in their genders, the countries in which their startups are located, the industries their startups serve, their age, their educational levels, their work experience as entrepreneurs, and the length of time the startups have been on the market. Collected data are analyzed using the Partial Least Squares Structural Equation Modeling (PLS-SEM) technique, which results in a statistical examination of the relationships between the adoption model’s factors. The results indicate that social influence, domain experience, technology familiarity, system quality, training and support, interaction convenience, and anthropomorphism are the factors that impact the pre-perception and perception phase of adoption. These factors motivate entrepreneurs to experiment more with the technology, thereby building perceptions of its usefulness, perceived ease of use, and perceived enjoyment, three factors that in turn affect emotions toward the technology and, finally, switching intentions. Control variables like age, gender, and educational attainment have no appreciable effect on switching intentions to alternatives of the Generative AI technology. Rather, the experience factor of running businesses shows itself to be a crucial one. The results have practical implications for entrepreneurs and other innovation ecosystem actors, including, for instance, technology providers, libraries, and policymakers. This research study enriches the Generative AI technology acceptance theory and extends the existing literature by introducing new adoption variables and stages specific to entrepreneurship.},
}

@article{Juergen2024,
  title = {Higher Education’s Generative Artificial Intelligence Paradox: The Meaning of Chatbot Mania},
  author = {Juergen Rudolph and Fadhil Mohamed Mohamed Ismail and Stefan Popenici},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/5821c044982322e2aebfbadbf319cdf7f6e576bf},
  abstract = {Higher education is currently under a significant transformation due to the emergence of generative artificial intelligence (GenAI) technologies, the hype surrounding GenAI and the increasing influence of educational technology business groups over tertiary education. This commentary, prepared for the Special Issue of the Journal of University Teaching & Learning Practice (JUTLP) on “Enhancing student engagement using Artificial Intelligence (AI) and chatbots,” delves into the complex landscape of opportunities and threats that AI chatbots, including ChatGPT, introduce to the realm of higher education. We argue that while GenAI offers promise in enhancing pedagogy, research, administration, and student support, concerns around academic integrity, labour displacement, embedded biases, environmental sustainability, increased commercialisation, and regulatory gaps necessitate a critical approach. Our commentary advocates for the development of critical AI literacy among educators and students, emphasising the necessity to foster an environment of responsible innovation and informed use of AI. We posit that the successful integration of AI in higher education must be grounded in the principles of ethics, equity, and the prioritisation of educational aims and human values. By offering a critical and nuanced exploration of these issues, our commentary aims to contribute to the ongoing discourse on how higher education institutions can navigate the rise of GenAI, ensuring that technological advancements benefit all stakeholders while upholding core academic values.},
}

@article{Ahmed2024,
  title = {Advancements and Applications of Generative Artificial Intelligence and Large Language Models on Business Management: A Comprehensive Review},
  author = {Ahmed Ali Linkon and Mujiba ✉ and Md Shohail Uddin Sarker and Norun Nabi and Md Nasir Uddin Rana and Sandip Kumar Ghosh and Mohammad Anisur Rahman and Hammed Esa and Faiaz Rahat Chowdhury},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/535dc052b6d65746d09ee866f826250e1042dc99},
  abstract = {This comprehensive review delves into the landscape and recent advancements of Generative Artificial Intelligence (AI) and Large Language Models (LLMs), shedding light on their transformative potential and applications across various sectors. Generative AI, exemplified by models like ChatGPT, DALL-E, and Midjourney, has rapidly evolved and is driven by breakthroughs in deep learning architectures and the availability of vast datasets. Concurrently, LLMs have revolutionized natural language processing tasks, utilizing vast text corpora to generate human-like text. The study explores recent developments, including the introduction of advanced models like GPT-4 and PaLM2 and the emergence of specialized LLMs like small LLMs (sLLMs), aimed at overcoming hardware limitations and cost constraints. Additionally, the expanding applications of generative AI, from healthcare to finance, underscore its transformative potential in addressing real-world challenges. Through a comprehensive analysis, this research contributes to the ongoing discourse on AI ethics, governance, and regulation, emphasizing the importance of responsible innovation for the benefit of humanity.},
}

@article{S.2024,
  title = {Generative Artificial Intelligence: A Systematic Review and Applications},
  author = {S. S. Sengar and Affan Bin Hasan and Sanjay Kumar and Fiona Carroll},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/5b8b994117d9d3273d91e9c671da495e9e20e889},
  abstract = {In recent years, the study of artificial intelligence (AI) has undergone a paradigm shift. This has been propelled by the groundbreaking capabilities of generative models both in supervised and unsupervised learning scenarios. Generative AI has shown state-of-the-art performance in solving perplexing real-world conundrums in fields such as image translation, medical diagnostics, textual imagery fusion, natural language processing, and beyond. This paper documents the systematic review and analysis of recent advancements and techniques in Generative AI with a detailed discussion of their applications including application-specific models. Indeed, the major impact that generative AI has made to date, has been in language generation with the development of large language models, in the field of image translation and several other interdisciplinary applications of generative AI. Moreover, the primary contribution of this paper lies in its coherent synthesis of the latest advancements in these areas, seamlessly weaving together contemporary breakthroughs in the field. Particularly, how it shares an exploration of the future trajectory for generative AI. In conclusion, the paper ends with a discussion of Responsible AI principles, and the necessary ethical considerations for the sustainability and growth of these generative models.},
}

@article{Eric2024,
  title = {Generative artificial intelligence, human creativity, and art},
  author = {Eric Zhou and Dokyun Lee},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/441922f7ed3a91c5ef9fdac7025bc67012a88815},
  abstract = {Abstract Recent artificial intelligence (AI) tools have demonstrated the ability to produce outputs traditionally considered creative. One such system is text-to-image generative AI (e.g. Midjourney, Stable Diffusion, DALL-E), which automates humans’ artistic execution to generate digital artworks. Utilizing a dataset of over 4 million artworks from more than 50,000 unique users, our research shows that over time, text-to-image AI significantly enhances human creative productivity by 25% and increases the value as measured by the likelihood of receiving a favorite per view by 50%. While peak artwork Content Novelty, defined as focal subject matter and relations, increases over time, average Content Novelty declines, suggesting an expanding but inefficient idea space. Additionally, there is a consistent reduction in both peak and average Visual Novelty, captured by pixel-level stylistic elements. Importantly, AI-assisted artists who can successfully explore more novel ideas, regardless of their prior originality, may produce artworks that their peers evaluate more favorably. Lastly, AI adoption decreased value capture (favorites earned) concentration among adopters. The results suggest that ideation and filtering are likely necessary skills in the text-to-image process, thus giving rise to “generative synesthesia”—the harmonious blending of human exploration and AI exploitation to discover new creative workflows.},
}

@article{Rong2024,
  title = {Teaching CS50 with AI: Leveraging Generative Artificial Intelligence in Computer Science Education},
  author = {Rong Liu and Carter Zenke and Charlie Liu and Andrew Holmes and Patrick Thornton and David J. Malan},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/0394864f253fd69284462664d5725ad6ba7aa6e1},
  abstract = {In Summer 2023, we developed and integrated a suite of AI-based software tools into CS50 at Harvard University. These tools were initially available to approximately 70 summer students, then to thousands of students online, and finally to several hundred on campus during Fall 2023. Per the course's own policy, we encouraged students to use these course-specific tools and limited the use of commercial AI software such as ChatGPT, GitHub Copilot, and the new Bing. Our goal was to approximate a 1:1 teacher-to-student ratio through software, thereby equipping students with a pedagogically-minded subject-matter expert by their side at all times, designed to guide students toward solutions rather than offer them outright. The tools were received positively by students, who noted that they felt like they had "a personal tutor.'' Our findings suggest that integrating AI thoughtfully into educational settings enhances the learning experience by providing continuous, customized support and enabling human educators to address more complex pedagogical issues. In this paper, we detail how AI tools have augmented teaching and learning in CS50, specifically in explaining code snippets, improving code style, and accurately responding to curricular and administrative queries on the course's discussion forum. Additionally, we present our methodological approach, implementation details, and guidance for those considering using these tools or AI generally in education.},
}

@article{Ahmad2024,
  title = {Student Perceptions of Generative Artificial Intelligence: Investigating Utilization, Benefits, and Challenges in Higher Education},
  author = {Ahmad Almassaad and Haya A. Alajlan and Reem Alebaikan},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/194fc8aeb4ae89175b5915f203a159b84ef6a97d},
  abstract = {This research explores the use of Generative Artificial Intelligence (GenAI) tools among higher education students in Saudi Arabia, aiming to understand their current perceptions of these technologies. This study utilizes the Technology Acceptance Model (TAM) and the theory of Task-Technology Fit (TTF) to examine students’ utilization, perceived benefits, and challenges associated with these tools. A cross-sectional survey was conducted, yielding 859 responses. The findings indicate that 78.7% of students frequently use GenAI tools, while 21.3% do not, often due to a lack of knowledge or interest. ChatGPT emerged as the most widely used GenAI tool, utilized by 86.2% of respondents, followed by other tools like Gemini, Socratic, and CoPilot. Students primarily use these tools for defining or clarifying concepts, translation, generating ideas in writing, and summarizing academic literature. They cite benefits such as ease of access, time-saving, and instant feedback. However, they express concerns about the challenges, including subscription fees, unreliable information, plagiarism, reduced human-to-human interaction, and impacts on learning autonomy. This study underscores the need for increased awareness, ethical guidelines, and robust academic integrity measures to ensure the responsible use of GenAI tools in educational settings. These findings highlight the need for a balanced utilization of GenAI tools in higher education that maximizes benefits while addressing potential challenges and guides the development of policies, curricula, and support systems.},
}

@article{Soumyadeb2024,
  title = {Generative Artificial Intelligence in Business: Towards a Strategic Human Resource Management Framework},
  author = {Soumyadeb Chowdhury and P. Budhwar and Geoffrey Wood},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/326b9ad69a7e60e84fbff2b1d2d2c858952b17fd},
  abstract = {As businesses and society navigate the potentials of generative artificial intelligence (GAI), the integration of these technologies introduces unique challenges and opportunities for human resources, requiring a re‐evaluation of human resource management (HRM) frameworks. The existing frameworks may often fall short of capturing the novel attributes, complexities and impacts of GAI on workforce dynamics and organizational operations. This paper proposes a strategic HRM framework, underpinned by the theory of institutional entrepreneurship for sustainable organizations, for integrating GAI within HRM practices to boost operational efficiency, foster innovation and secure a competitive advantage through responsible practices and workforce development. Central to this framework is the alignment with existing business objectives, seizing opportunities, strategic resource assessment and orchestration, re‐institutionalization, realignment and embracing a culture of continuous learning and adaptation. This approach provides a detailed roadmap for organizations to navigate successfully the complexities of a GAI‐enhanced business environment. Additionally, this paper significantly contributes to the theoretical discourse by bridging the gap between HRM and GAI adoption, the proposed framework accounting for GAI–human capital symbiosis, setting the stage for future research to empirically test its applicability, explore its implications on HRM practices and understand its broader economic and societal consequences through diverse multi‐disciplinary and multi‐level research methodologies.},
}

@article{Siu-Cheung2024,
  title = {A pedagogical design for self-regulated learning in academic writing using text-based generative artificial intelligence tools: 6-P pedagogy of plan, prompt, preview, produce, peer-review, portfolio-tracking},
  author = {Siu-Cheung Kong and John Chi-Kin Lee and Olson Tsang},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/8ed3851a65e1a649a439cf0e2cd192939558c479},
  abstract = {The emergence and popularity of generative artificial intelligence (AI) tools, particularly text-based ones known as large language models, pose both opportunities and challenges to education. The ability of these tools to generate human-like texts based on minimal instructions causes concerns among educators about students’ use of these tools for academic writing, which may constitute a breach of academic integrity. We propose a pedagogical design that models on self-regulated learning and the authoring cycle and develops students’ critical thinking and self-regulation when composing academic writing using text-based generative AI tools. It contains six iterative and interactive phases. Students first plan the content and structure of the writing, then generate prompts for text-based generative AI tools. Next, students preview and verify the tools’ output, followed by the fourth phase of producing the writing using the corrected output. Fifthly, peer review by fellow students may be required to polish and proofread the writing. Lastly, through portfolio-tracking, students reflect on the writing process, and formulate strategies for future usage of text-based generative AI tools for writing. This pedagogical design helps students and teachers embrace text-based generative AI while addressing the perils these tools present, and guides the development of education interventions and instruments.},
}

@article{Jeff2024,
  title = {Understanding the role and impact of Generative Artificial Intelligence (AI) hallucination within consumers’ tourism decision-making processes},
  author = {Jeff Christensen and Jared M. Hansen and Paul Wilson},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/88cdca57a248f7d1d9a0667834dc9f9af24bd2be},
  abstract = {ABSTRACT ChatGPT, which launched only a year ago, is the fastest-growing website in the world today. When generative AI software such as ChatGPT generates ideas for people, they often generate false ideas. This occurrence has been called ‘AI Hallucination’. It can include generating false text output that is extremely believable to completely gibberish. This source of potential misinformation has significant potential implications for the travel and tourism industry. Using survey responses from 900 consumers, this empirical study contributes to theorizing and examination of how consumers’ awareness of AI Hallucination potential combines with existing concepts from the Technology Acceptance Model (TAM) and Theory of Planned Behaviour (TPB) when it comes to the decision to use generative AI platforms such as ChatGPT for tourism planning. This research also examines if the consumers are actually able to discern AI Hallucination and why they select to use AI technologies over other tourism information sources, such as aggregated peer review websites like TripAdvisor, government tourism websites, or social media influencers. The results indicate that many consumers chose error-filled AI tourism itineraries over other options because they trust the AI to be more impartial and customized than the other sources.},
}

@article{Tomas2024,
  title = {Generative artificial intelligence of things systems, multisensory immersive extended reality technologies, and algorithmic big data simulation and modelling tools in digital twin industrial metaverse},
  author = {Tomas Kliestik and Pavol Král and M. Bugaj and Pavol Durana},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/6befb74b06980a1b9bf2cec0dfa2502452ffabf4},
  abstract = {Research background: Multi-modal synthetic data fusion and analysis, simulation and modelling technologies, and virtual environmental and location sensors shape the industrial metaverse. Visual digital twins, smart manufacturing and sensory data mining techniques, 3D digital twin simulation modelling and predictive maintenance tools, big data and mobile location analytics, and cloud-connected and spatial computing devices further immersive virtual spaces, decentralized 3D digital worlds, synthetic reality spaces, and the industrial metaverse.
Purpose of the article: We aim to show that big data computing and extended cognitive systems, 3D computer vision-based production and cognitive neuro-engineering technologies, and synthetic data interoperability improve artificial intelligence-based digital twin industrial metaverse and hyper-immersive simulated environments. Geolocation data mining and tracking tools, image processing computational and robot motion algorithms, and digital twin and virtual immersive technologies shape the economic and business management of extended reality environments and the industrial metaverse.
Methods: Quality tools: AMSTAR, BIBOT, CASP, Catchii, R package and Shiny app citationchaser, DistillerSR, JBI SUMARI, Litstream, Nested Knowledge, Rayyan, and Systematic Review Accelerator. Search period: April 2024. Search terms: “digital twin industrial metaverse” + “artificial Intelligence of Things systems”, “multisensory immersive extended reality technologies”, and “algorithmic big data simulation and modelling tools”. Selected sources: 114 out of 336. Published research inspected: 2022–2024. PRISMA was the reporting quality assessment tool. Dimensions and VOSviewer were deployed as data visualization tools.
Findings & value added: Simulated augmented reality and multi-sensory tracking technologies, explainable artificial intelligence-based decision support and cloud-based robotic cooperation systems, and ambient intelligence and deep learning-based predictive analytics modelling tools are instrumental in augmented reality environments and in the industrial metaverse. The economic and business management of the industrial metaverse necessitates connected enterprise production and big data computing systems, simulation and modelling technologies, and virtual reality-embedded digital twins.},
}

@article{T.2024,
  title = {A classification tool to foster self-regulated learning with generative artificial intelligence by applying self-determination theory: a case of ChatGPT},
  author = {T. Chiu},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/d69953ae182aaa1925a56c5ffe8c8be14f7c6cc8},
  abstract = {Generative AI such as ChatGPT provides an instant and individualized learning environment, and may have the potential to motivate student self-regulated learning (SRL), more effectively than other non-AI technologies. However, the impact of ChatGPT on student motivation, SRL, and needs satisfaction is unclear. Motivation and the SRL process can be explained using self-determination theory (SDT) and the three phases of forethought, performance, and self-reflection, respectively. Accordingly, a Delphi design was employed in this study to determine how ChatGPT-based learning activities satisfy students’ each SDT need, and foster each SRL phase from a teacher perspective. We involved 36 SDT school teachers with extensive expertise in technology enhanced learning to develop a classification tool for learning activities that affect student needs satisfaction and SRL phases using ChatGPT. We collaborated with the teachers in three rounds to investigate and identify the activities, and we revised labels, descriptions, and explanations. The major finding is that a classification tool for 20 learning activities using ChatGPT was developed. The tool suggests how ChatGPT better satisfy SDT-based needs, and fosters the three SRL phrases. This classification tool can assist researchers in replicating, implementing, and integrating successful ChatGPT in education research and development projects. The tool can inspire teachers to modify the activities using generative AI for their own teaching, and inform policymakers on how to develop guidelines for AI in education.},
}

@article{Amit2024,
  title = {Generative artificial intelligence in drug discovery: basic framework, recent advances, challenges, and opportunities},
  author = {Amit Gangwal and Azim Ansari and I. Ahmad and Abul Kalam Azad and V. Kumarasamy and Vetriselvan Subramaniyan and L. S. Wong},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/8cface791b3f369c9da3109c57040295b4c4e7eb},
  abstract = {There are two main ways to discover or design small drug molecules. The first involves fine-tuning existing molecules or commercially successful drugs through quantitative structure-activity relationships and virtual screening. The second approach involves generating new molecules through de novo drug design or inverse quantitative structure-activity relationship. Both methods aim to get a drug molecule with the best pharmacokinetic and pharmacodynamic profiles. However, bringing a new drug to market is an expensive and time-consuming endeavor, with the average cost being estimated at around $2.5 billion. One of the biggest challenges is screening the vast number of potential drug candidates to find one that is both safe and effective. The development of artificial intelligence in recent years has been phenomenal, ushering in a revolution in many fields. The field of pharmaceutical sciences has also significantly benefited from multiple applications of artificial intelligence, especially drug discovery projects. Artificial intelligence models are finding use in molecular property prediction, molecule generation, virtual screening, synthesis planning, repurposing, among others. Lately, generative artificial intelligence has gained popularity across domains for its ability to generate entirely new data, such as images, sentences, audios, videos, novel chemical molecules, etc. Generative artificial intelligence has also delivered promising results in drug discovery and development. This review article delves into the fundamentals and framework of various generative artificial intelligence models in the context of drug discovery via de novo drug design approach. Various basic and advanced models have been discussed, along with their recent applications. The review also explores recent examples and advances in the generative artificial intelligence approach, as well as the challenges and ongoing efforts to fully harness the potential of generative artificial intelligence in generating novel drug molecules in a faster and more affordable manner. Some clinical-level assets generated form generative artificial intelligence have also been discussed in this review to show the ever-increasing application of artificial intelligence in drug discovery through commercial partnerships.},
}

@article{Marcello2024,
  title = {Generative artificial intelligence in innovation management: A preview of future research developments},
  author = {Marcello M. Mariani and Yogesh K. Dwivedi},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/552bbc2c5014c5229ed751e474ff7f49d27ee0ba},
}

@article{Locky2024,
  title = {Application of generative artificial intelligence (GenAI) in language teaching and learning: A scoping literature review},
  author = {Locky Law},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/4ff15a48ea0d0e402ea089ccd5a36087b612198e},
}

@article{Ruchi2024,
  title = {Adoption and impacts of generative artificial intelligence: Theoretical underpinnings and research agenda},
  author = {Ruchi Gupta and Kiran Nair and Mahima Mishra and Blend Ibrahim and Seema Bhardwaj},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/d095c8477525ce07f8c7a08cc36f02916a2320a6},
}

@article{J.2024,
  title = {Generative Artificial Intelligence to Transform Inpatient Discharge Summaries to Patient-Friendly Language and Format},
  author = {J. Zaretsky and Jeong Min Kim and Samuel Baskharoun and Yunan Zhao and Jonathan S. Austrian and Yindalon Aphinyanaphongs and Ravi Gupta and S. B. Blecker and Jonah Feldman},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/88241c65981eaf814108a57b5bc22ea9573da969},
  abstract = {Key Points Question Can a large language model transform discharge summaries into a format that is more readable and understandable for patients? Findings In this cross-sectional study of 50 discharge summaries, understandability scores were significantly higher for patient-friendly discharge summaries. Summaries were rated entirely complete in 56 of 100 reviews, but 18 reviews noted safety concerns involving omissions and inaccuracies. Meaning These findings suggest that a large language model could be used to translate discharge summaries into patient-friendly language and format, but implementation will require improvements in accuracy, completeness, and safety.},
}

@article{M.2024,
  title = {The ChatGPT Effect: Nursing Education and Generative Artificial Intelligence.},
  author = {M. Topaz and Laura-Maria Peltonen and Martin Michalowski and Gregor Stiglic and C. Ronquillo and Lisiane Pruinelli and Jiyoun Song and Siobhán O'Connor and Shoko Miyagawa and Hiroki Fukahori},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/5326f0b6882ee8c1043e718b007c3595858f48fe},
}

@article{Yuwei2024,
  title = {Using Call Annie as a Generative Artificial Intelligence Speaking Partner for Language Learners},
  author = {Yuwei Wan and Benjamin Luke Moorhouse},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/6c9ace1890ffa47a070d806254250cb30dd57c81},
  abstract = {Developing English speaking skills can be challenging for many English language learners. The advent of generative artificial intelligence (GAI) has prompted the emergence of a growing number of artificial intelligence (AI)-powered chatbots designed to tackle these challenges. One popular tool is ‘Call Annie,’ a GAI video chatbot that can act as a virtual assistant, enabling users to engage in immersive video calls with AI avatars. This technology review discusses its functionality, how it can be used in supporting learners’ language development, how teachers can collaborate with it in class and its potential limitations.},
}

@article{P.2024,
  title = {Cardiovascular care with digital twin technology in the era of generative artificial intelligence.},
  author = {P. Thangaraj and Sean H Benson and E. Oikonomou and F. Asselbergs and R. Khera},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/5a84d9a03dd422de6a5c9e9cbbd0ea93dd1c4f56},
  abstract = {Digital twins, which are in silico replications of an individual and its environment, have advanced clinical decision-making and prognostication in cardiovascular medicine. The technology enables personalized simulations of clinical scenarios, prediction of disease risk, and strategies for clinical trial augmentation. Current applications of cardiovascular digital twins have integrated multi-modal data into mechanistic and statistical models to build physiologically accurate cardiac replicas to enhance disease phenotyping, enrich diagnostic workflows, and optimize procedural planning. Digital twin technology is rapidly evolving in the setting of newly available data modalities and advances in generative artificial intelligence, enabling dynamic and comprehensive simulations unique to an individual. These twins fuse physiologic, environmental, and healthcare data into machine learning and generative models to build real-time patient predictions that can model interactions with the clinical environment to accelerate personalized patient care. This review summarizes digital twins in cardiovascular medicine and their potential future applications by incorporating new personalized data modalities. It examines the technical advances in deep learning and generative artificial intelligence that broaden the scope and predictive power of digital twins. Finally, it highlights the individual and societal challenges as well as ethical considerations that are essential to realizing the future vision of incorporating cardiology digital twins into personalized cardiovascular care.},
}

@article{Jenelle2024,
  title = {Ensuring useful adoption of generative artificial intelligence in healthcare},
  author = {Jenelle A Jindal and M. Lungren and Nigam H. Shah},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/a63b0864afb934b2b5ffd032e89fbb7c0d4932a3},
  abstract = {OBJECTIVES
This article aims to examine how generative artificial intelligence (AI) can be adopted with the most value in health systems, in response to the Executive Order on AI.


MATERIALS AND METHODS
We reviewed how technology has historically been deployed in healthcare, and evaluated recent examples of deployments of both traditional AI and generative AI (GenAI) with a lens on value.


RESULTS
Traditional AI and GenAI are different technologies in terms of their capability and modes of current deployment, which have implications on value in health systems.


DISCUSSION
Traditional AI when applied with a framework top-down can realize value in healthcare. GenAI in the short term when applied top-down has unclear value, but encouraging more bottom-up adoption has the potential to provide more benefit to health systems and patients.


CONCLUSION
GenAI in healthcare can provide the most value for patients when health systems adapt culturally to grow with this new technology and its adoption patterns.},
}

@article{Lihui2024,
  title = {Does Generative Artificial Intelligence Improve the Academic Achievement of College Students? A Meta-Analysis},
  author = {Lihui Sun and Liang Zhou},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/d2095344b9d7a0fd8b5955630c356b19da523c22},
  abstract = {The use of generative artificial intelligence (Gen-AI) to assist college students in their studies has become a trend. However, there is no academic consensus on whether Gen-AI can enhance the academic achievement of college students. Using a meta-analytic approach, this study aims to investigate the effectiveness of Gen-AI in improving the academic achievement of college students and to explore the effects of different moderating variables. A total of 28 articles (65 independent studies, 1909 participants) met the inclusion criteria for this study. The results showed that Gen-AI significantly improved college students’ academic achievement with a medium effect size (Hedges’s g = 0.533, 95% CI [0.408,0.659], p < .05). There were within-group differences in the three moderator variables, activity categories, sample size, and generated content, when the generated content was text (g = 0.554, p < .05), and sample size of 21–40 (g = 0.776, p < .05), the use of independent learning styles (g = 0.600, p < .05) had the most significant improvement in college student’s academic achievement. The intervention duration, the discipline types, and the assessment tools also had a moderate positive impact on college students’ academic achievement, but there were no significant within-group differences in any of the moderating variables. This study provides a theoretical basis and empirical evidence for the scientific application of Gen-AI and the development of educational technology policy.},
}

@article{Rommel2024,
  title = {Opportunities and Challenges of Integrating Generative Artificial Intelligence in Education},
  author = {Rommel Alali and Yousef Wardat},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/8287358ed0aa68d3062b5cf2d6b8d9a6bcabff38},
  abstract = {This paper thoroughly examines both the opportunities and obstacles associated with integrating Generative Artificial Intelligence (AI) into educational settings. It explores how Generative AI has the potential to enrich learning experiences, customize education for individuals, and foster creativity. However, it also confronts several challenges including ethical dilemmas, safeguarding data privacy, mitigating algorithmic biases, and reshaping the role of educators. Through a synthesis of theoretical frameworks and empirical research, the paper offers valuable insights into effective strategies for navigating these challenges. It emphasizes the importance of establishing ethical guidelines, ensuring transparency in algorithms, and adopting inclusive design principles during AI integration. Furthermore, the paper underscores the importance of providing educators with adequate training and professional development opportunities to effectively utilize AI tools. Additionally, it advocates for ongoing dialogue among stakeholders—such as educators, policymakers, technologists, and students—to steer responsible AI integration in education. Ultimately, the paper advocates for a collaborative approach that prioritizes human-centric values, equity, and diversity. While Generative AI holds promise for revolutionizing educational practices, its integration requires thoughtful consideration of ethical, social, and pedagogical implications. Through proactive collaboration and partnership, educators can leverage AI's potential to create more immersive, tailored, and equitable learning environments. },
}

@article{K.2024,
  title = {Generative Artificial Intelligence in Higher Education: Exploring Ways of Harnessing Pedagogical Practices with the Assistance of ChatGPT},
  author = {K. Nikolopoulou},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/600112f1df7a5805848d24efcc4c687d4581aca3},
  abstract = {There is a growing interest in using generative artificial intelligence (AI) for educational purposes within the higher education environments, while AI applications (such as ChatGPT) can transform traditional teaching and learning methods. ChatGPT is an advanced AI tool that generates new content and human-like responses. The purpose of this paper is to use ChatGPT as a research assistant in order to explore ways AI can be harnessed to enhance pedagogical practices in higher education. This is a qualitative study, in which the output-responses generated by ChatGPT provided a starting point for the investigation. AI can be harnessed to enhance pedagogical practices in higher education in various ways including personalized learning, automated assessment and feedback generation, virtual assistants and chatbots, content creation, resource recommendation, time management, language translation and support, research assistance, simulations and virtual labs. Other educational affordances that can strengthen the teaching and learning experience regard collaboration and communication, accessibility and inclusivity, as well as AI literacy. When implementing AI tools such as ChatGPT in higher education, ethical considerations (e.g., data privacy, transparency, accessibility, cultural sensitivity), potential misuses and concerns need to also be addressed. Although ChatGPT can aid the generation of content-ideas for further exploration, it is a complementary-supportive tool, and its output necessitates human evaluation and review. The integration of ChatGPT and other AI tools in the higher educational process/practices has implications for educators, students, design of curricula, and university policy makers.},
}

@article{Sandra2024,
  title = {Impacts of Generative Artificial Intelligence in Higher Education: Research Trends and Students’ Perceptions},
  author = {Sandra Saúde and João-Paulo Barros and Inês Almeida},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/9c556e6aa0167fb3c3e8c9509b9fa085b4e443b2},
  abstract = {In this paper, the effects of the rapid advancement of generative artificial intelligence (Gen AI) in higher education (HE) are discussed. A mixed exploratory research approach was employed to understand these impacts, combining analysis of current research trends and students’ perceptions of the effects of Gen AI tools in academia. Through bibliometric analysis and systematic literature review, 64 publications (indexed in the SCOPUS and Web of Science databases) were examined, highlighting Gen AI’s disruptive effect on the pedagogical aspects of HE. The impacts identified by the literature were compared with the perceptions held by computer science students of two different HE institutions (HEIs) on the topic. An exploratory study was developed based on the application of a questionnaire to a group of 112 students. The results suggest that while Gen AI can enhance academic work and learning feedback, it requires appropriate pedagogical support to foster critical, ethical, and digital literacy competencies. Students demonstrate awareness of both the risks and benefits associated with Gen AI in academic settings. The research concludes that failing to recognize and effectively use Gen AI in HE impedes educational progress and the adequate preparation of citizens and workers to think and act in an AI-mediated world.},
}

@article{Muhammad2024,
  title = {Factors affecting generative artificial intelligence, such as ChatGPT, use in higher education: An application of technology acceptance model},
  author = {Muhammad Farrukh Shahzad and Shuo Xu and Muhammad Asif},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/a13bbde142ea866156a8ae8b1801fb6179c9ffd2},
  abstract = {The adoption of generative artificial intelligence (GAI) tools, such as ChatGPT, in higher education presents numerous opportunities and challenges. The use of GAI technologies in various fields, including education, has accelerated as technology develops. The widely used language model ChatGPT, developed by OpenAI, has become progressively more important, especially in the field of education. This study employs the technology acceptance model to investigate the factors influencing the employment of ChatGPT within the higher education sector of Pakistan. This study employed the PLS‐SEM method for probing data collected from 368 Pakistani university students. The findings indicate that ChatGPT trust positively mediates the affiliation between ChatGPT self‐efficacy, ChatGPT actual use, ChatGPT use for information and ChatGPT use for interaction. Further, ChatGPT usefulness and ChatGPT ease of use significantly moderate the association between ChatGPT self‐efficacy and ChatGPT trust. Educators must encourage students to use ChatGPT safely to preserve their critical thinking, problem‐solving abilities and creativity during assessments. This study contributes to understanding generative AI tools such as ChatGPT that are used in educational settings and provides insights for administrators and policymakers aiming to implement these technologies effectively.},
}

@article{Jiacheng2024,
  title = {Generative Artificial Intelligence Assisted Wireless Sensing: Human Flow Detection in Practical Communication Environments},
  author = {Jiacheng Wang and Hongyang Du and Dusist Niyato and Zehui Xiong and Jiawen Kang and Bo Ai and Zhu Han and Dong In Kim},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/209d51c3753fddfc5f5b7d158dadb9bc67ecb3e0},
  abstract = {Groundbreaking applications such as ChatGPT have heightened research interest in generative artificial intelligence (GAI). Essentially, GAI excels not only in content generation but also signal processing, offering support for wireless sensing. Hence, we introduce a novel GAI-assisted human flow detection system (G-HFD). Rigorously, G-HFD first uses the channel state information (CSI) to estimate the velocity and acceleration of propagation path length change of the human induced reflection (HIR). Then, given the strong inference ability of the diffusion model, we propose a unified weighted conditional diffusion model (UW-CDM) to denoise the estimation results, enabling detection of the number of targets. Next, we use the CSI obtained by a uniform linear array with wavelength spacing to estimate the HIR’s time of flight and direction of arrival (DoA). In this process, UW-CDM solves the problem of ambiguous DoA spectrum, ensuring accurate DoA estimation. Finally, through clustering, G-HFD determines the number of subflows and the number of targets in each subflow, i.e., the subflow size. The evaluation based on practical downlink communication signals shows G-HFD’s accuracy of subflow size detection can reach 91%. This validates its effectiveness and underscores the significant potential of GAI in the context of wireless sensing.},
}

@article{Shaofeng2024,
  title = {Promoting sustainable development goals through generative artificial intelligence in the digital supply chain: Insights from Chinese tourism SMEs},
  author = {Shaofeng Wang and Hao Zhang},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/4e3cf7e4bf27ead052eba05720c133276a12286c},
  abstract = {Interdisciplinary advancements, such as generative artificial intelligence (AI) and digital supply chains, can significantly contribute to achieving sustainable development goals (SDGs), particularly within tourism. This paper illuminates how it works well, focusing on the underexplored area of Environmental, Social, and Governance (ESG) performance within small and medium‐sized tourism enterprises (SMEs) in China. Through a survey of 429 international SMEs, we apply the Resource‐Based View and Dynamic Capabilities Theory to investigate how generative AI, such as ChatGPT, in digital supply chains can enhance innovation, collaboration, and, ultimately, ESG performance. The empirical findings underscore the pivotal role of generative AI in augmenting ESG performance via bolstering innovation and collaboration within digital supply chains. Additionally, the moderating effect of customer involvement positively influences the relationship between the digital supply chain and ESG performance. By demonstrating these relations, our study contributes to theoretical and practical efforts toward sustainable tourism and the broader achievement of the SDGs.},
}

@article{Stephanie2024,
  title = {Clinical Reasoning of a Generative Artificial Intelligence Model Compared With Physicians.},
  author = {Stephanie Cabral and Daniel Restrepo and Zahir Kanjee and Philip Wilson and Byron Crowe and Raja-Elie Abdulnour and A. Rodman},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/7b57051e28a38319d0395f579266f883cbdd2149},
}

@article{Khadijeh2024,
  title = {Generative artificial intelligence in healthcare: A scoping review on benefits, challenges and applications},
  author = {Khadijeh Moulaei and Atiye Yadegari and Mahdi Baharestani and Shayan Farzanbakhsh and Babak Sabet and Mohammadreza Afrash},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/bd327d3b9048a731ec1cf0452d25573d4688fdbf},
}

@article{Jasper2024,
  title = {Do you create your content yourself? Using generative artificial intelligence for social media content creation diminishes perceived brand authenticity},
  author = {Jasper David Brüns and Martin Meißner},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/24e4866a7596680e6b3e4a37c5de2c475dd33eb9},
}

@article{I.2024,
  title = {Conversational and generative artificial intelligence and human-chatbot interaction in education and research},
  author = {I. Akpan and Y. Kobara and Josiah Owolabi and A. A. Akpan and Onyebuchi Felix Offodile},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/f34d918d8630dd1adce642f7f2bea3e2eaeb7f76},
  abstract = {Artificial intelligence (AI) as a disruptive technology is not new. However, its recent evolution, engineered by technological transformation, big data analytics, and quantum computing, produces conversational and generative AI (CGAI/GenAI) and human‐like chatbots that disrupt conventional operations and methods in different fields. This study investigates the scientific landscape of CGAI and human–chatbot interaction/collaboration and evaluates use cases, benefits, challenges, and policy implications for multidisciplinary education and allied industry operations. The publications trend showed that just 4% (n = 75) occurred during 2006–2018, while 2019–2023 experienced astronomical growth (n = 1763 or 96%). The prominent use cases of CGAI (e.g., ChatGPT) for teaching, learning, and research activities occurred in computer science (multidisciplinary and AI; 32%), medical/healthcare (17%), engineering (7%), and business fields (6%). The intellectual structure shows strong collaboration among eminent multidisciplinary sources in business, information systems, and other areas. The thematic structure highlights prominent CGAI use cases, including improved user experience in human–computer interaction, computer programs/code generation, and systems creation. Widespread CGAI usefulness for teachers, researchers, and learners includes syllabi/course content generation, testing aids, and academic writing. The concerns about abuse and misuse (plagiarism, academic integrity, privacy violations) and issues about misinformation, danger of self‐diagnoses, and patient privacy in medical/healthcare applications are prominent. Formulating strategies and policies to address potential CGAI challenges in teaching/learning and practice are priorities. Developing discipline‐based automatic detection of GenAI contents to check abuse is proposed. In operational/operations research areas, proper CGAI/GenAI integration with modeling and decision support systems requires further studies.},
}

@article{Reinhard2024,
  title = {Performance of Generative Artificial Intelligence in Dental Licensing Examinations},
  author = {Reinhard Chun Wang Chau and K. M. Thu and O. Y. Yu and R. T. Hsung and Edward Chin Man Lo and W. Y. Lam},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/721a205fc8882095e0fab660ecea12786882663e},
}

@article{Zied2023,
  title = {Transforming Education: A Comprehensive Review of Generative Artificial Intelligence in Educational Settings through Bibliometric and Content Analysis},
  author = {Zied Bahroun and Chiraz Anane and Vian Ahmed and Andrew Zacca},
  year = {2023},
  url = {https://www.semanticscholar.org/paper/c5ab57bc7dd7695e699b017f4efebc78a77897ec},
  abstract = {In the ever-evolving era of technological advancements, generative artificial intelligence (GAI) emerges as a transformative force, revolutionizing education. This review paper, guided by the PRISMA framework, presents a comprehensive analysis of GAI in education, synthesizing key insights from a selection of 207 research papers to identify research gaps and future directions in the field. This study begins with a content analysis that explores GAI’s transformative impact in specific educational domains, including medical education and engineering education. The versatile applications of GAI encompass assessment, personalized learning support, and intelligent tutoring systems. Ethical considerations, interdisciplinary collaboration, and responsible technology use are highlighted, emphasizing the need for transparent GAI models and addressing biases. Subsequently, a bibliometric analysis of GAI in education is conducted, examining prominent AI tools, research focus, geographic distribution, and interdisciplinary collaboration. ChatGPT emerges as a dominant GAI tool, and the analysis reveals significant and exponential growth in GAI research in 2023. Moreover, this paper identifies promising future research directions, such as GAI-enhanced curriculum design and longitudinal studies tracking its long-term impact on learning outcomes. These findings provide a comprehensive understanding of GAI’s potential in reshaping education and offer valuable insights to researchers, educators, and policymakers interested in the intersection of GAI and education.},
}

@article{Zengyi2024,
  title = {Research on Generative Artificial Intelligence for Virtual Financial Robo-Advisor},
  author = {Zengyi Huang and Chang Che and Haotian Zheng and Chen Li},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/59667c186ab9b5ac7ba81e21b4d2c021efa83740},
  abstract = {This research explores the intersection of artificial intelligence and finance, focusing on the emergence of intelligent investment advisers, commonly known as Robo-advisers (RAs). These RAs utilize robust computer models and artificial intelligence algorithms to deliver personalized asset management investment plans for users. Notably, Wealthfront is highlighted as a prominent platform in this field, offering automated investment management services aimed at optimizing investment returns. The study investigates the impact of users' past investment performance on their adoption of intelligent advisers, considering factors such as previous defaults and recent investment performance. It reveals that frequent adjustments to the use of intelligent advisers may hinder long-term investment objectives, emphasizing the importance of consistent usage to fully capitalize on their benefits. Furthermore, the research emphasizes the significance of transparency, user-friendly interaction design, and tailored financial services to foster user trust and enhance the optimization of intelligent advisers' design.},
}

@article{Anil2024,
  title = {Generative Artificial Intelligence and Evaluating Strategic Decisions},
  author = {Anil R. Doshi and J. J. Bell and Emil Mirzayev and Bart S. Vanneste},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/1b43632036f7e1f45a4759849f2924478eccc81e},
  abstract = {Strategic decisions are uncertain and often irreversible. Hence, predicting the value of alternatives is important for strategic decision making. We investigate the use of generative artificial intelligence (AI) in evaluating strategic alternatives using business models generated by AI (study 1) or submitted to a competition (study 2). Each study uses a sample of 60 business models and examines agreement in business model rankings made by large language models (LLMs) and those by human experts. We consider multiple LLMs, assumed LLM roles, and prompts. We find that generative AI often produces evaluations that are inconsistent and biased. However, when aggregating evaluations, AI rankings tend to resemble those of human experts. This study highlights the value of generative AI in strategic decision making by providing predictions.Managers are seeking to create value by integrating generative AI into their organizations. We show how managers can use generative AI to help evaluate strategic decisions. Generative AI's single evaluations are often inconsistent or biased. However, if managers aggregate many evaluations across LLMs, prompts, or roles, the results show that the resulting evaluations tend to resemble those of human experts. This approach allows managers to obtain insight on strategic decisions across a variety of domains with relatively low investments in time or resources, which can be combined with human inputs.},
}

@article{Yilin2024,
  title = {EmoEden: Applying Generative Artificial Intelligence to Emotional Learning for Children with High-Function Autism},
  author = {Yilin Tang and Liuqing Chen and Ziyu Chen and Wenkai Chen and Yu Cai and Yao Du and Fan Yang and Lingyun Sun},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/70f979dc1022b94cead18236aa40077eea5500b7},
  abstract = {Children with high-functioning autism (HFA) often face challenges in emotional recognition and expression, leading to emotional distress and social difficulties. Conversational agents developed for HFA children in previous studies show limitations in children's learning effectiveness due to the conversational agents’ inability to dynamically generate personalized and contextual content. Recent advanced generative Artificial Intelligence techniques, with the capability to generate substantial diverse and high-quality texts and visual content, offer an opportunity for personalized assistance in emotional learning for HFA children. Based on the findings of our formative study, we integrated large language models and text-to-image models to develop a tool named EmoEden supporting children with HFA. Over a 22-day study involving six HFA children, it is observed that EmoEden effectively engaged children and improved their emotional recognition and expression abilities. Additionally, we identified the advantages and potential risks of applying generative AI to assist HFA children in emotional learning.},
}

@article{Grant2024,
  title = {Pixels and Pedagogy: Examining Science Education Imagery by Generative Artificial Intelligence},
  author = {Grant Cooper and Kok‐Sing Tang},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/53002b879a021386ebab1cdea60470492746fcb7},
  abstract = {The proliferation of generative artificial intelligence (GenAI) means we are witnessing transformative change in education. While GenAI offers exciting possibilities for personalised learning and innovative teaching methodologies, its potential for reinforcing biases and perpetuating stereotypes poses ethical and pedagogical concerns. This article aims to critically examine the images produced by the integration of DALL-E 3 and ChatGPT, focusing on representations of science classrooms and educators. Applying a capital lens, we analyse how these images portray forms of culture (embodied, objectified and institutionalised) and explore if these depictions align with, or contest, stereotypical representations of science education. The science classroom imagery showcased a variety of settings, from what the GenAI described as vintage to contemporary. Our findings reveal the presence of stereotypical elements associated with science educators, including white-lab coats, goggles and beakers. While the images often align with stereotypical views, they also introduce elements of diversity. This article highlights the importance for ongoing vigilance about issues of equity, representation, bias and transparency in GenAI artefacts. This study contributes to broader discourses about the impact of GenAI in reinforcing or dismantling stereotypes associated with science education.},
}

@article{Kiduk2024,
  title = {Updated Primer on Generative Artificial Intelligence and Large Language Models in Medical Imaging for Medical Professionals},
  author = {Kiduk Kim and Kyungjin Cho and Ryoungwoo Jang and Sunggu Kyung and Soyoung Lee and S. Ham and Edward Choi and G. Hong and Namkug Kim},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/7cce514d89e74ebdab205e0a0cb44080c0d8e0c2},
  abstract = {The emergence of Chat Generative Pre-trained Transformer (ChatGPT), a chatbot developed by OpenAI, has garnered interest in the application of generative artificial intelligence (AI) models in the medical field. This review summarizes different generative AI models and their potential applications in the field of medicine and explores the evolving landscape of Generative Adversarial Networks and diffusion models since the introduction of generative AI models. These models have made valuable contributions to the field of radiology. Furthermore, this review also explores the significance of synthetic data in addressing privacy concerns and augmenting data diversity and quality within the medical domain, in addition to emphasizing the role of inversion in the investigation of generative models and outlining an approach to replicate this process. We provide an overview of Large Language Models, such as GPTs and bidirectional encoder representations (BERTs), that focus on prominent representatives and discuss recent initiatives involving language-vision models in radiology, including innovative large language and vision assistant for biomedicine (LLaVa-Med), to illustrate their practical application. This comprehensive review offers insights into the wide-ranging applications of generative AI models in clinical research and emphasizes their transformative potential.},
}

@article{Morteza2024,
  title = {Generative artificial intelligence in manufacturing: opportunities for actualizing Industry 5.0 sustainability goals},
  author = {Morteza Ghobakhloo and Masood Fathi and Mohammad Iranmanesh and Mantas Vilkas and Andrius Grybauskas and A. Amran},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/2ea12f6beb2d504b985503e945526a85251ed3af},
  abstract = {PurposeThis study offers practical insights into how generative artificial intelligence (AI) can enhance responsible manufacturing within the context of Industry 5.0. It explores how manufacturers can strategically maximize the potential benefits of generative AI through a synergistic approach.Design/methodology/approachThe study developed a strategic roadmap by employing a mixed qualitative-quantitative research method involving case studies, interviews and interpretive structural modeling (ISM). This roadmap visualizes and elucidates the mechanisms through which generative AI can contribute to advancing the sustainability goals of Industry 5.0.FindingsGenerative AI has demonstrated the capability to promote various sustainability objectives within Industry 5.0 through ten distinct functions. These multifaceted functions address multiple facets of manufacturing, ranging from providing data-driven production insights to enhancing the resilience of manufacturing operations.Practical implicationsWhile each identified generative AI function independently contributes to responsible manufacturing under Industry 5.0, leveraging them individually is a viable strategy. However, they synergistically enhance each other when systematically employed in a specific order. Manufacturers are advised to strategically leverage these functions, drawing on their complementarities to maximize their benefits.Originality/valueThis study pioneers by providing early practical insights into how generative AI enhances the sustainability performance of manufacturers within the Industry 5.0 framework. The proposed strategic roadmap suggests prioritization orders, guiding manufacturers in decision-making processes regarding where and for what purpose to integrate generative AI.},
}

@article{Y.2024,
  title = {Balancing Innovation and Regulation in the Age of Generative Artificial Intelligence},
  author = {Y. Wu and Xukang Wang},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/e96f0bfaf89e1c9a979ebbbd06f3c8e1f0b5d19c},
  abstract = {
 The emergence of generative artificial intelligence (AI), exemplified by models like ChatGPT, presents both opportunities and challenges. As these technologies become increasingly integrated into various aspects of society, the need for a harmonized legal framework to address the associated risks becomes crucial. This article presents a comprehensive analysis of the disruptive impact of generative AI, the legal risks of AI-generated content, and the governance strategies needed to strike a balance between innovation and regulation. Employing a three-pronged methodology—literature review, doctrinal legal analysis, and case study integration—the study examines the current legal landscape; synthesizes scholarly works on the technological, ethical, and socioeconomic implications of generative AI; and illustrates practical challenges through real-world case studies. The article assesses the strengths and limitations of US governance strategies for AI and proposes a harmonized legal framework emphasizing international collaboration, proactive legislation, and the establishment of a dedicated regulatory body. By engaging diverse stakeholders and identifying critical gaps in current research, the study contributes to the development of a legal framework that upholds ethical principles, protects individual rights, and fosters responsible innovation in the age of generative AI.},
}

@article{Peng2024,
  title = {E-waste challenges of generative artificial intelligence},
  author = {Peng Wang and Ling-Yu Zhang and A. Tzachor and Weiqiang Chen},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/c7a0efe4dc9060b45a6a1eb44ffbedb818635077},
}

@article{Rong2024,
  title = {PlantoGraphy: Incorporating Iterative Design Process into Generative Artificial Intelligence for Landscape Rendering},
  author = {Rong Huang and Haichuan Lin and Chuanzhang Chen and Kang Zhang and Wei Zeng},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/b5710193dc676e0b9043f00759d776d10d3f6ea5},
  abstract = {Landscape renderings are realistic images of landscape sites, allowing stakeholders to perceive better and evaluate design ideas. While recent advances in Generative Artificial Intelligence (GAI (generative artificial intelligence)) enable automated generation of landscape renderings, the End to End (endtoend) methods are not compatible with common design processes, leading to insufficient alignment with design idealizations and limited cohesion of iterative landscape design. Informed by a formative study for comprehending design requirements, we present PlantoGraphy, an iterative design system that allows for interactive configuration of generative artificial intelligence models to accommodate human-centered design practice. A two-stage pipeline is incorporated: first, the concretization module transforms conceptual ideas into concrete scene layouts with a domain-oriented large language model; and second, the illustration module converts scene layouts into realistic landscape renderings with a layout-guided diffusion model Fine-tune (finetune)ed through Low-Rank Adaptation (LoRA) (lora). PlantoGraphy has undergone a series of performance evaluations and user studies, demonstrating its effectiveness in landscape rendering generation and the high recognition of its interactive functionality.},
}

@article{G.2024,
  title = {Generative Artificial Intelligence Biases, Limitations and Risks in Nuclear Medicine: An Argument for Appropriate Use Framework and Recommendations.},
  author = {G. Currie and K. E. Hawk and Eric M. Rohren},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/3fa00e6eae6083ef312a95e7ce8eb01bc9ecbefd},
  abstract = {Generative artificial intelligence (AI) algorithms for both text-to-text and text-to-image applications have seen rapid and widespread adoption in the general and medical communities. While limitations of generative AI have been widely reported, there remain valuable applications in patient and professional communities. Here, the limitations and biases of both text-to-text and text-to-image generative AI are explored using purported applications in medical imaging as case examples. A direct comparison of the capabilities of four common text-to-image generative AI algorithms is reported and recommendations for the most appropriate use, DALL-E 3, justified. The risks use and biases are outlined, and appropriate use guidelines framed for use of generative AI in nuclear medicine. Generative AI text-to-text and text-to-image generation includes inherent biases, particularly gender and ethnicity, that could misrepresent nuclear medicine. The assimilation of generative AI tools into medical education, image interpretation, patient education, health promotion and marketing in nuclear medicine risks propagating errors and amplification of biases. Mitigation strategies should reside inside appropriate use criteria and minimum standards for quality and professionalism for the application of generative AI in nuclear medicine.},
}

@article{Yanhua2024,
  title = {Using generative artificial intelligence/ChatGPT for academic communication: Students' perspectives},
  author = {Yanhua Liu and Jaeuk Park and Sean McMinn},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/fa8ba85f52b8461acda289897cc22bc37a537b60},
  abstract = {Generative artificial intelligence (GenAI) tools such as ChatGPT with their human‐like intelligence and language processing capabilities are significantly impacting the way we live, work, and communicate with each other. While scholars have increasingly focused on the use of GenAI in higher education since its inception, little is known about how key higher education stakeholders, particularly students, perceive its impact on teaching and learning within the context of academic communication, an area central to students' development of transferable skills and literacy competencies yet heavily influenced by the technology. This empirical study addresses the gap by investigating students' experiences and attitudes toward GenAI tools for English academic communication, focusing on their overall perceptions, perceived benefits, limitations, and challenges. Drawing on data from a questionnaire survey with 475 students and interviews with 12 at two universities in China, our findings indicate that students generally view GenAI positively, considering them useful for learning academic communication skills, particularly in writing, grammar, vocabulary, and reading. However, limitations are recognized in terms of giving feedback on critical thinking, creativity, and speaking skills. In addition, information reliability, ethical issues, and impact on assessment and academic integrity also emerged as important concerns. Our study argues that universities should embrace and capitalize on the affordances of GenAI and address its challenges to better support students' learning of critical academic literacy.},
}

@article{Matthew2024,
  title = {Analysis of Recommender System Using Generative Artificial Intelligence: A Systematic Literature Review},
  author = {Matthew O. Ayemowa and Roliana Ibrahim and Muhammad Murad Khan},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/7e80b89e1035955ee11c43b8fafc12ae9e2900fd},
  abstract = {Recommender Systems (RSs), which generate personalized content, have become a technological tool with diverse applications for users. While numerous RSs have been proposed and successfully implemented across various domains, traditional AI-based RSs still encounter certain challenges, such as data sparsity, cold start, and diversity. Generative Artificial Intelligence in recommender systems is a recent advancement used by platforms like Netflix, Spotify, and Amazon to recommend items, news, videos, audios, goods, and services to their customers/users or to personalize experiences for their customers/users. The main purpose of this review is to compare traditional AI-based recommender systems with generative AI-based recommender systems. A total of fifty-two (52) papers, published between 2019 and February 2024, were selected from six major online libraries. To get a more comprehensive understanding of the selected study, we reviewed the selected studies techniques, and the models, datasets, and metrics used. Our systematic review reveals that generative AI models, such as generative adversarial networks (GANs), variational autoencoder (VAEs) and autoencoders have been widely used in recommender systems and they perform better than traditional AI techniques. Among the 30 datasets analyzed, MovieLens was the most frequently used, accounting for 33%, while Amazon datasets accounted for 11%, Recall and RSME are the most commonly used metrics. Our literature review offers understandings into the Generative AI techniques used across different recommender systems and provides suggestions for the future research. Finally, we elaborated on open issues and discussed current and future trends in generative AI-based recommendation systems.},
}

@article{Xin2024,
  title = {Factors Influencing University Students' Behavioural Intention to Use Generative Artificial Intelligence for Educational Purposes Based on a Revised UTAUT2 Model},
  author = {Xin Tang and Zhiqiang Yuan and Shaojun Qu},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/0ecf2395e920fac80321d9bf2e32f0465bf4986c},
  abstract = {Generative artificial intelligence (AI) represents a significant technological leap, with platforms like OpenAI's ChatGPT and Baidu's Ernie Bot at the forefront of innovation. This technology has seen widespread adoption across various sectors of society and is anticipated to revolutionise the educational landscape, especially in the domain of tertiary education. However, there is a gap in understanding factors influencing university students' behavioural intention to use generative AI, leading to hesitation in its adoption.The primary objective of this study was to investigate the factors that influence university students' behavioural intention to engage with and utilise generative AI. The study sought to delve into the fundamental reasons and obstacles that university students encounter when contemplating the adoption of this technology for their academic endeavours.The study used a quantitative research design, utilising a revised version of the Unified Theory of Acceptance and Use of Technology 2 (UTAUT2) model. Data were collected from a sample of 380 university students in Changsha, the capital city of Hunan in China. Partial least squares structural equation modelling (PLS‐SEM) was used to analyse the relationships between the variables of the model, which included performance expectancy (PE), effort expectancy (EE), social influence (SI), facilitating conditions (FC), learning value, habit and behavioural intention.The analysis revealed that PE and EE have a direct impact on learning value. Additionally, SI and FC were found to directly affect the formation of habit. Among these factors, learning value emerged as the most potent predictor of university students' behavioural intention to use generative AI. Habit also demonstrated a significant, albeit smaller, effect on behavioural intention.The study's findings underscore the importance of learning value in driving the adoption of generative AI among university students. Efforts to enhance the learning value of generative AI could significantly increase its uptake in higher education. Furthermore, the role of habit, while less pronounced, suggests that consistent exposure and use can foster a greater inclination towards generative AI. These insights provide a foundation for targeted interventions aimed at improving the integration and application of generative AI within educational settings. Stakeholders, including educators, policymakers and designers of generative AI, can leverage these findings to create an environment conducive to the adoption and effective use of generative AI in higher education.},
}

@article{Laurie2024,
  title = {Generative Artificial Intelligence: 8 Critical Questions for Libraries},
  author = {Laurie M. Bridges and Kelly McElroy and Zach Welhouse},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/612d6b515942d09dba0d8803d44d7fa00983528e},
  abstract = {Abstract In this article, we provide a brief overview of generative artificial intelligence (GenAI) and large language models (LLMs). We then propose eight critical questions that libraries should ask when exploring this technology and its implications for their communities. We argue that libraries have a unique role in facilitating informed and responsible use of GenAI, as well as safeguarding and promoting the values of access, privacy, and intellectual freedom.},
}

@article{Ha2024,
  title = {The double‐edged sword of generative artificial intelligence in digitalization: An affordances and constraints perspective},
  author = {Ha Eun (Grace) Park},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/eab2ff58bb1414ac3cad17519dfb82eed3489691},
  abstract = {Generative artificial intelligence (AI) has gained prominence across various industries and domains, offering capabilities to generate human‐like text, creative ideas, and solutions. This paper explores customers' responses to the use of generative AI in digitalizing content production and consumption processes. Drawing on technology affordance theory, this article examines how are the affordances of generative AI leveraged to contribute to the gradual digitalization of individuals. This netnographic study is based on over 9 months naturalistic observations of the AI Community online, culminating in 1572 pages of data. The findings identify different types of affordances that foster digitalization: automated content creation, automated data analysis, and AI‐generated content dissemination. This study also identifies the constraints of generative AI and discusses potential interventions to address these constraints and prevent unintended consequences. This research provides insights for scholars, professionals, and educators to better understand the dynamics of leveraging generative AI.},
}

@article{Jan2024,
  title = {Comparing the Ideation Quality of Humans With Generative Artificial Intelligence},
  author = {Jan Joosten and Volker Bilgram and Alexander Hahn and Dirk Totzek},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/c695768e83d4c70a3f496205e95f2f68c4ff3bdd},
  abstract = {Traditionally, ideating new product innovations is primarily the responsibility of marketers, engineers, and designers. However, a rapidly growing interest lies in leveraging generative artificial intelligence (AI) to brainstorm new product and service ideas. This study conducts a comparative analysis of ideas generated by human professionals and an AI system. The results of a blind expert evaluation show that AI-generated ideas score significantly higher in novelty and customer benefit, while their feasibility scores are similar to those of human ideas. Overall, AI-generated ideas comprise the majority of the top-performing ideas, while human-generated ideas scored lower than expected. The executive's emotional and cognitive reactions were measured during the evaluation to check for potential biases and showed no differences between the idea groups. These findings suggest that, under certain circumstances, companies can benefit from integrating generative AI into their traditional idea-generation processes.},
}

@article{Kok‐Sing2024,
  title = {The Role of Materiality in an Era of Generative Artificial Intelligence},
  author = {Kok‐Sing Tang and Grant Cooper},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/60bba8dba3b5d763c73d59b5d66be81498545efd},
  abstract = {The introduction of generative artificial intelligence (GenAI) tools like ChatGPT has raised many challenging questions about the nature of teaching, learning, and assessment in every subject area, including science. Unlike other disciplines, natural science is unique because the ontological and epistemological understanding of nature is fundamentally rooted in our interaction with material objects in the physical world. GenAI, powered by statistical probability arising from a massive corpus of text, is devoid of any connection to the physical world. The use of GenAI thus raises concerns about our connection to reality and its effect on science education. This paper emphasizes the importance of materiality (or material reality) in shaping scientific knowledge and argues for its recognition in the era of GenAI. Drawing on the perspectives of new materialism and science studies, the paper highlights how materiality forms an indispensable aspect of human knowledge and meaning-making, particularly in the discipline of science. It further explains how materiality is central to the epistemic authority of science and cautions the outputs generated by GenAI that lack contextualization to a material reality. The paper concludes by providing recommendations for research and teaching that recognize the role of materiality in the context of GenAI, specifically in practical work, scientific argumentation, and learning with GenAI. As we navigate a future dominated by GenAI, understanding how the epistemic authority of science arises from our connection to the physical world will become a crucial consideration in science education.},
}

@article{Nguyen2024,
  title = {A Generative Artificial Intelligence Using Multilingual Large Language Models for ChatGPT Applications},
  author = {Nguyen Trung Tuan and Philip Moore and Dat Ha Vu Thanh and H. V. Pham},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/017d852fc59ddbe82f3e32e627f35530a388ca94},
  abstract = {ChatGPT plays significant roles in the third decade of the 21st Century. Smart cities applications can be integrated with ChatGPT in various fields. This research proposes an approach for developing large language models using generative artificial intelligence models suitable for small- and medium-sized enterprises with limited hardware resources. There are many generative AI systems in operation and in development. However, the technological, human, and financial resources required to develop generative AI systems are impractical for small- and medium-sized enterprises. In this study, we present a proposed approach to reduce training time and computational cost that is designed to automate question–response interactions for specific domains in smart cities. The proposed model utilises the BLOOM approach as its backbone for using generative AI to maximum the effectiveness of small- and medium-sized enterprises. We have conducted a set of experiments on several datasets associated with specific domains to validate the effectiveness of the proposed model. Experiments using datasets for the English and Vietnamese languages have been combined with model training using low-rank adaptation to reduce training time and computational cost. In comparative experimental testing, the proposed model outperformed the `Phoenix’ multilingual chatbot model by achieving a 92% performance compared to `ChatGPT’ for the English benchmark.},
}

@article{Hyunkyoung2024,
  title = {Students’ use of generative artificial intelligence for proving mathematical statements},
  author = {Hyunkyoung Yoon and Jihye Hwang and Kyungwon Lee and Kyeong Hah Roh and Oh Nam Kwon},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/3a3bcba373ad70b66f3a65e6576425e553d2e1d5},
  abstract = {In this exploratory study, we investigate undergraduate students’ engagement with generative Artificial Intelligence (genAI) in proving mathematical statements. We selected six mathematical statements to conduct interviews with three students. We present the emergent framework, Students’ Interactive Proving Experience with AI (SIPE-AI), which explains the processes of students’ use of genAI in their proving and the factors influencing these processes. Our findings identify three factors that shape students’ use of genAI: conceptions of proof, conceptions of genAI, and ethical considerations. The results suggest a need to guide undergraduate students in critically engaging with genAI tools, rather than passively accepting their outputs. We also discuss the implications of these findings for enhancing undergraduate mathematics education by fostering informed and critical use of genAI in mathematical proving.},
}

@article{Mohammed2024,
  title = {Generative artificial intelligence and the personalization of health professional education: A narrative review},
  author = {Mohammed Almansour and F. Alfhaid},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/6ddfe8622e6ef9eda621205a01fb7f97669ca79e},
  abstract = {This narrative review examined the intersection of generative artificial intelligence (GAI) and the personalization of health professional education (PHE). This review aims to the elucidate the current condition of GAI technologies and their particular uses in the field of PHE. Data were extracted and analyzed from studies focusing on the demographics and professional development preferences of healthcare workers, the competencies required for personalized precision medicine, and the current and potential applications of artificial intelligence (AI) in PHE. The review also addressed the ethical implications of AI implementation in this context. Findings indicated a gender-balanced healthcare workforce with a predisposition toward continuous professional development and digital tool utilization. A need for a comprehensive educational framework was identified to include a spectrum of skills crucial for precision medicine, emphasizing the importance of patient involvement and bioethics. AI was found to enhance educational experiences and research in PHE, with an increasing trend in AI applications, particularly in surgical education since 2018. Ethical challenges associated with AI integration in PHE were highlighted, with an emphasis on the need for ethical design and diverse development teams. Core concepts in AI research were established, with a spotlight on emerging areas such as data science and learning analytics. The application of AI in PHE was recognized for its current benefits and potential for future advancements, with a call for ethical vigilance. GAI holds significant promise for personalizing PHE, with an identified need for ethical frameworks and diverse developer teams to address bias and equity in educational AI applications.},
}

@article{Sadi2024,
  title = {Generative artificial intelligence in ophthalmology: current innovations, future applications and challenges},
  author = {Sadi Can Sonmez and Mertcan Sevgi and F. Antaki and Josef Huemer and P. Keane},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/ffb7ddd32f1dca2f4d72747eb91d41f32ad445ed},
  abstract = {The rapid advancements in generative artificial intelligence are set to significantly influence the medical sector, particularly ophthalmology. Generative adversarial networks and diffusion models enable the creation of synthetic images, aiding the development of deep learning models tailored for specific imaging tasks. Additionally, the advent of multimodal foundational models, capable of generating images, text and videos, presents a broad spectrum of applications within ophthalmology. These range from enhancing diagnostic accuracy to improving patient education and training healthcare professionals. Despite the promising potential, this area of technology is still in its infancy, and there are several challenges to be addressed, including data bias, safety concerns and the practical implementation of these technologies in clinical settings.},
}

@article{Alessia2024,
  title = {Generative artificial intelligence and ELT},
  author = {Alessia Cogo and Laura Patsko and Joanna Szoke},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/c3db0b63c8582981a69055692ba1cf5ad89d9ddc},
  abstract = {
 There is undoubtedly, and understandably, a growing interest in incorporating generative artificial intelligence (GenAI) technologies into ELT. While advanced AI models have the potential to support language education, offering new tools and resources to enhance learning, their use also raises important questions regarding ethics and responsibility. As we follow the emergence of GenAI as another ELT tool, it is crucial to strike a balance between leveraging the benefits of these technologies and maintaining the core values of effective pedagogy. Educators must develop clear guidelines and best practices for the responsible integration of AI in the classroom, ensuring that it enhances rather than replaces human interaction and critical thinking. In this Special Issue on GenAI and ELT we explore some of the applications, their potential, and the challenges of incorporating GenAI in ELT.},
}

@article{Ahmed2024,
  title = {Generative Artificial Intelligence in Patient Education: ChatGPT Takes on Hypertension Questions},
  author = {Ahmed Almagazzachi and Ahmed Mustafa and Ashkan Eighaei Sedeh and Andres E Vazquez Gonzalez and Anastasiia Polianovskaia and Muhanad Abood and Ameer Abdelrahman and Veronica Muyolema Arce and Talar Acob and Bushra Saleem},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/afd0725098881024ea34630e426abd41dd79dd06},
  abstract = {Introduction Uncontrolled hypertension significantly contributes to the development and deterioration of various medical conditions, such as myocardial infarction, chronic kidney disease, and cerebrovascular events. Despite being the most common preventable risk factor for all-cause mortality, only a fraction of affected individuals maintain their blood pressure in the desired range. In recent times, there has been a growing reliance on online platforms for medical information. While providing a convenient source of information, differentiating reliable from unreliable information can be daunting for the layperson, and false information can potentially hinder timely diagnosis and management of medical conditions. The surge in accessibility of generative artificial intelligence (GeAI) technology has led to increased use in obtaining health-related information. This has sparked debates among healthcare providers about the potential for misuse and misinformation while recognizing the role of GeAI in improving health literacy. This study aims to investigate the accuracy of AI-generated information specifically related to hypertension. Additionally, it seeks to explore the reproducibility of information provided by GeAI. Method A nonhuman-subject qualitative study was devised to evaluate the accuracy of information provided by ChatGPT regarding hypertension and its secondary complications. Frequently asked questions on hypertension were compiled by three study staff, internal medicine residents at an ACGME-accredited program, and then reviewed by a physician experienced in treating hypertension, resulting in a final set of 100 questions. Each question was posed to ChatGPT three times, once by each study staff, and the majority response was then assessed against the recommended guidelines. A board-certified internal medicine physician with over eight years of experience further reviewed the responses and categorized them into two classes based on their clinical appropriateness: appropriate (in line with clinical recommendations) and inappropriate (containing errors). Descriptive statistical analysis was employed to assess ChatGPT responses for accuracy and reproducibility. Result Initially, a pool of 130 questions was gathered, of which a final set of 100 questions was selected for the purpose of this study. When assessed against acceptable standard responses, ChatGPT responses were found to be appropriate in 92.5% of cases and inappropriate in 7.5%. Furthermore, ChatGPT had a reproducibility score of 93%, meaning that it could consistently reproduce answers that conveyed similar meanings across multiple runs. Conclusion ChatGPT showcased commendable accuracy in addressing commonly asked questions about hypertension. These results underscore the potential of GeAI in providing valuable information to patients. However, continued research and refinement are essential to evaluate further the reliability and broader applicability of ChatGPT within the medical field.},
}

@article{Xinhua2024,
  title = {A Study of the Factors Influencing Teachers' Willingness to Use Generative Artificial Intelligence Based on the UTAUT Model},
  author = {Xinhua Zhang and Thitinant Wareewanich},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/f751e8fd8e06d4f4547cfcd505cdcc3e6e4d6a32},
  abstract = {The advancement of wireless communication and mobile computing technologies has paved the way for the extensive application of Artificial Intelligence across diverse sectors, including electronics, automotive, medical, industrial, and educational fields. Employing the Unified Theory of Acceptance and Use of Technology, this study investigates the key determinants influencing preschool teachers’ willingness to utilize Generative Artificial Intelligence (GAI) in Jiangsu Province, China. The research, involving 154 participants, analyzes their inclination towards GAI adoption through four dimensions: performance expectancy, effort expectancy, social influence, and facilitating conditions. Findings reveal that performance expectancy, social influence, and facilitating conditions significantly enhance their willingness to adopt GAI. Additionally, teaching experience and IT proficiency were found to moderate the effects of certain variables on this willingness. This aligns with the broader goal of integrating digital technology into education, which is a vital element of the nexus between digital technology development and innovation.},
}

@article{D.2024,
  title = {Designing experiential learning activities with generative artificial intelligence tools for authentic assessment},
  author = {D. Salinas-Navarro and E. Vilalta-Perdomo and Rosario Michel-Villarreal and Luis Montesinos},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/2529d2f2ecb644d7b2842940a3d04046078f2350},
  abstract = {
Purpose
This article investigates the application of generative artificial intelligence (GenAI) in experiential learning for authentic assessment in higher education. Recognized for its human-like content generation, GenAI has garnered widespread interest, raising concerns regarding its reliability, ethical considerations and overall impact. The purpose of this study is to explore the transformative capabilities and limitations of GenAI for experiential learning.


Design/methodology/approach
The study uses “thing ethnography” and “incremental prompting” to delve into the perspectives of ChatGPT 3.5, a prominent GenAI model. Through semi-structured interviews, the research prompts ChatGPT 3.5 on critical aspects such as conceptual clarity, integration of GenAI in educational settings and practical applications within the context of authentic assessment. The design examines GenAI’s potential contributions to reflective thinking, hands-on learning and genuine assessments, emphasizing the importance of responsible use.


Findings
The findings underscore GenAI’s potential to enhance experiential learning in higher education. Specifically, the research highlights GenAI’s capacity to contribute to reflective thinking, hands-on learning experiences and the facilitation of genuine assessments. Notably, the study emphasizes the significance of responsible use in harnessing the capabilities of GenAI for educational purposes.


Originality/value
This research showcases the application of GenAI in operations management education, specifically within lean health care. The study offers insights into its capabilities by exploring the practical implications of GenAI in a specific educational domain through thing ethnography and incremental prompting. Additionally, the article proposes future research directions, contributing to the originality of the work and opening avenues for further exploration in the integration of GenAI in education.
},
}

@article{Kristin2024,
  title = {Generative Artificial Intelligence in Product Design Education: Navigating Concerns of Originality and Ethics},
  author = {Kristin A. Bartlett and J. Camba},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/99c2ba6717264cfd998cac2f9735fda90538a556},
  abstract = {Image-generative artificial intelligence (AI) is increasingly being used in the product design process. In this paper, we present examples of how it is being used and discuss the possibilities of how applications may evolve in the future. We discuss the legal and ethical implications of image-generative AI, including concerns about bias, hidden labor, theft from artists, lack of originality in the outputs, and lack of copyright protection. We discuss how these concerns apply to design education and provide recommendations to educators about how AI should be addressed in the design classroom. We recommend that educators introduce AI as one tool among many in the designer’s toolkit and encourage it to be used as a process tool rather than for generating final design deliverables. We also provide guidance for how educators might engage students in discussions about AI to enhance their learning.},
}

@article{Thomas2024,
  title = {Start Generating: Harnessing Generative Artificial Intelligence for Sociological Research},
  author = {Thomas R. Davidson},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/7c1954c5bdac4bc3a2dd6e2a01113c6c416c9e4d},
  abstract = {How can generative artificial intelligence (GAI) be used for sociological research? The author explores applications to the study of text and images across multiple domains, including computational, qualitative, and experimental research. Drawing upon recent research and stylized experiments with DALL·E and GPT-4, the author illustrates the potential applications of text-to-text, image-to-text, and text-to-image models for sociological research. Across these areas, GAI can make advanced computational methods more efficient, flexible, and accessible. The author also emphasizes several challenges raised by these technologies, including interpretability, transparency, reliability, reproducibility, ethics, and privacy, as well as the implications of bias and bias mitigation efforts and the trade-offs between proprietary models and open-source alternatives. When used with care, these technologies can help advance many different areas of sociological methodology, complementing and enhancing our existing toolkits.},
}

@article{Federico2024,
  title = {When AIs become oracles: generative artificial intelligence, anticipatory urban governance, and the future of cities},
  author = {Federico Cugurullo and Ying Xu},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/be0180a415861fe85626e7080caeda9fc339823e},
  abstract = {
 Generative Artificial Intelligence (AI) is boosting anticipatory forms of governance, through which state actors seek to predict the future and strategically intervene in the present. In this context, city brains represent an emerging type of generative AI currently employed in urban governance and public policy in a growing number of cities. City brains are large-scale AIs residing in vast digital urban platforms, which manage multiple urban domains including transport, safety, health, and environmental monitoring. They use Large Language Models (LLMs) to generate visions of urban futures: visions that are in turn used by policymakers to generate new urban policies. In this paper, we advance a twofold contribution. Theoretically, we develop a critical theory of anticipatory governance in the age of generative AI. More specifically, we focus on technocratic approaches to anticipatory governance, to explain how the act of governing extends into the future by means of predictive AI technology. Our approach is critical in order to expose the dangers that the use of AI (generative AI, in particular) in urban governance poses, and to identify their causes. These dangers include the formation of a policy process that, under the influence of unintelligible LLMs, risks losing transparency and thus accountability, and the marginalization of human stakeholders (citizens, in particular) as the role of AI in the management of cities keeps growing and governance begins to turn posthuman. Empirically, we critically examine an existing city brain project under development in China and ground our critical theory in a real-life example.},
}

@article{D.2024,
  title = {Generative artificial intelligence in higher education learning: A review based on academic databases},
  author = {D. Andrade-Girón and W. Marín-Rodriguez and Juana Sandivar-Rosas and Edgardo Carreño-Cisneros and E. Susanibar-Ramirez and Marcelo Zúñiga-Rojas and Julio Ángeles-Morales and Henry Villarreal-Torres},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/7e0b228695280f5a022c8583fc6eb76931db8dd3},
  abstract = {Objective. The rapid integration of Generative Artificial Intelligence (AI), especially tools like ChatGPT, into educational sectors has spurred significant academic interest. This review article provides a systematic examination of the current scholarly landscape concerning the use of ChatGPT within higher education. 
Design/Methodology/Approach. Drawing from a range of academic databases between 2022 and 2024, we meticulously adhere to PRISMA guidelines, evaluating a final set of 28 out of 1740 initial articles based on predetermined inclusion and exclusion criteria. 
Results/Discussion. Our analysis reveals diverse global contributions predominantly from Asia and identifies a prevalent quantitative research approach among the studies. We delve into the selected articles' geographical distribution, methodologies, and thematic outcomes, highlighting a notable lack of research from Latin America. The review critically assesses the validity, utility, and time optimization aspects of ChatGPT in educational settings, uncovering a positive impact on student learning and time management. However, we pinpoint a significant gap in rigorous experimental research, underscoring the need for studies with random sampling and controlled settings to enhance the external validity of findings. Additionally, we call attention to the ethical considerations and the necessity for higher education institutions to adapt teaching methodologies to incorporate AI effectively. 
Conclusion. The article concludes with recommendations for future research to address the identified gaps and optimize the educational use of generative AI technologies like ChatGPT.},
}

@article{Daniel2024,
  title = {Harnessing generative artificial intelligence to support nature‐based solutions},
  author = {Daniel Richards and David Worden and Xiaoping Song and Sandra Lavorel},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/f74249c9f799cdff6571f927d793ec9dfd8f37b2},
  abstract = {


The ongoing biodiversity and climate change crises require society to adopt nature‐based solutions that integrate and enhance ecosystems. To achieve successful implementation of nature‐based solutions, it is vital to communicate scientific information about their benefits and suitability.

This article explores the potential of generative artificial intelligence (GenAI) as a tool for automating and scaling up science communication, outreach, and extension for nature‐based solutions.

To illustrate the potential of GenAI, we present three case study examples; (1) reporting scientific information on ecosystem services, future land use options, and nature‐based solutions for farms (2) interactively providing guidance in response to homeowner questions about biodiversity‐friendly garden design and (3) visualising potential future scenarios of landscape change that incorporate diverse nature based and technological solutions. These examples demonstrate potential applications which may be relevant to other systems and types of nature‐based solutions.

While GenAI for nature‐based solutions offers significant opportunities, this new technology brings risks of bias, false information, data privacy, mistrust, and high energy usage. Alongside technological development, we require integrated social research into ethics, public acceptability, and user experience, to maximise the benefits of GenAI while limiting these risks.

GenAI offers an opportunity to accelerate the dissemination of nature‐based design strategies and reach a broader audience, by synthesising information and producing tailored content for specific users and locations. By harnessing the power of GenAI alongside human expertise, we can support nature‐based solutions to tackle the complex challenges of future sustainability.

Read the free Plain Language Summary for this article on the Journal blog.},
}

@article{Deepak2024,
  title = {Exploring the Potential of Generative Artificial Intelligence},
  author = {Deepak Kumar Sahu},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/c71010b49ea104e9adc95869819aae8d39746afe},
  abstract = {Generative artificial intelligence is a cutting-edge technology that creates new content in a variety of media which includes text, graphics, and music, just like human creativity. To fully explore the possibilities of generative AI, this research article discusses the underlying technologies of Transformer models, Variational autoencoder (VAEs), and Generative Adversarial Networks (GANs). It explores the various uses of generative AI in IT operations, data augmentation, and natural language processing, emphasizing how it is revolutionizing these fields. With an emphasis on responsible AI use, ethical issues about privacy problems and biases in created information are also covered. To demonstrate the field's ongoing development, recent developments in generative AI—such as Sora and DEVIN AI—are reviewed. The goal of this paper is to shed light on how generative AI may transform several industries while properly addressing societal issues.},
}

@article{S.2024,
  title = {A study on the impact of Generative Artificial Intelligence supported Situational Interactive Teaching on students’ ‘flow’ experience and learning effectiveness — a case study of legal education in China},
  author = {S. Shi and J.W. Li and R. Zhang},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/25e3dafef45cf78e5a4f0fa9aeaa3a4ec0dc4d99},
  abstract = {ABSTRACT The rapid advancement of Generative Artificial Intelligence Technology has increasingly drawn attention to its potential applications in the educational sector. This study aims to investigate the effects of Situational Interactive Teaching, facilitated by generative artificial intelligence, on students’ learning outcomes and flow experiences. A series of experiments were designed to compare the performance of a Generative Artificial Intelligence-supported Situational Interactive Teaching Method with a Traditional Video Interactive Teaching Method. Data was collected using research tools such as questionnaires and test questions to assess students’ cognitive levels, learning effectiveness, flow experiences, and subjective evaluations during the instructional process. The analysis revealed distinct differences between the two teaching methods. The findings suggest that compared to traditional teaching methods, Generative Artificial Intelligence-supported Situational Interactive Teaching significantly improves students’ learning outcomes in cognitive, skill, and affective domains, while also enhancing flow experiences. These positive effects are not limited by individual student differences, indicating broad applicability. Furthermore, this teaching approach can foster a positive feedback loop between learning effectiveness and flow experience. In conclusion, this study confirms the effective application of generative artificial intelligence technology in legal education, providing empirical evidence for the promotion of this innovative teaching model in the educational field.},
}

@article{Joel2024,
  title = {Adapting Self-Regulated Learning in an Age of Generative Artificial Intelligence Chatbots},
  author = {Joel Weijia Lai},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/9b16afdda1773ad54dc97fc3929378410c7aa8d6},
  abstract = {The increasing use of generative artificial intelligence (GenAI) has led to a rise in conversations about how teachers and students should adopt these tools to enhance the learning process. Self-regulated learning (SRL) research is important for addressing this question. A popular form of GenAI is the large language model chatbot, which allows users to seek answers to their queries. This article seeks to adapt current SRL models to understand student learning with these chatbots. This is achieved by classifying the prompts supplied by a learner to an educational chatbot into learning actions and processes using the process–action library. Subsequently, through process mining, we can analyze these data to provide valuable insights for learners, educators, instructional designers, and researchers into the possible applications of chatbots for SRL.},
}

@article{Chun2024,
  title = {Misinformation and Literacies in the Era of Generative Artificial Intelligence: A Brief Overview and a Call for Future Research},
  author = {Chun Chu-Ke and Yujie Dong},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/2f71d2d47a61f943ca058cfb4dccd9c0915658db},
  abstract = {Misinformation constitutes a societal practice and challenge that necessitates unwavering attention worldwide. In this essay, we discussed the theoretical advancement and empirical evidence in misinformation research, encompassing a review of definitions of misinformation, research orientations, research perspectives, and vulnerable groups. We then reviewed the misinformation fueled by generative artificial intelligence (AI) and the evolving conceptualization of literacy. To counter AI-fueled misinformation, we argue that the development of ethical AI necessitates regulations from AI practitioners and legislation, and ethical uses of AI require efforts in AI literacy education and research. The AI literacy should include (a) users’ understanding and critical evaluation of knowledge, values, and cultures within which AI systems function, and their implications on the AI-generated content, (b) users’ strategic interpretation and proper use of AI-generated content, and (c) users’ utilization of feedback mechanisms to promote institutional management of the AI power.},
}

@article{S.2024,
  title = {Framework for Adoption of Generative Artificial Intelligence (GenAI) in Education},
  author = {S. Shailendra and Rajan Kadel and Aakanksha Sharma},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/59075d1ab338a44a6046bb4c3bd9d0990e01a3fb},
  abstract = {Contributions: An adoption framework to include generative artificial intelligence (GenAI) in the university curriculum. It identifies and highlights the role of different stakeholders (university management, students, staff, etc.) during the adoption process. It also proposes an objective approach based upon an evaluation matrix to assess the success and outcome of the GenAI adoption. Background: Universities worldwide are debating and struggling with the adoption of GenAI in their curriculum. GenAI has impacted our perspective on traditional methods of academic integrity and the scholarship of teaching, learning, and research. Both the faculty and students are unsure about the approach in the absence of clear guidelines through the administration and regulators. This requires an established framework to define a process and articulate the roles and responsibilities of each stakeholder involved. Research Questions: Whether the academic ecosystem requires a methodology to adopt GenAI into its curriculum? A systematic approach for the academic staff to ensure the students’ learning outcomes are met with the adoption of GenAI. How to measure and communicate the adoption of GenAI in the university setup? Methodology: The methodology employed in this study focuses on examining the university education system and assessing the opportunities and challenges related to incorporating GenAI in teaching and learning. Additionally, it identifies a gap and the absence of a comprehensive framework that obstructs the effective integration of GenAI within the academic environment. Findings: The literature survey results indicate the limited or no adoption of GenAI by the university, which further reflects the dilemma in the minds of different stakeholders. For the successful adoption of GenAI, a standard framework is proposed 1) for effective redesign of the course curriculum; 2) for enabling staff and students; and 3) to define an evaluation matrix to measure the effectiveness and success of the adoption process.},
}

@article{Xue2024,
  title = {Using social learning theories to explore the role of generative Artificial Intelligence (AI) in collaborative learning},
  author = {Xue Zhou and Lilian N. Schofield},
  year = {2024},
  url = {https://www.semanticscholar.org/paper/dc0bc86f932123f91db40efe3533a6ef441613ad},
  abstract = {This opinion piece highlights the integral role of generative Artificial Intelligence (AI) in learning within Higher Education Institutions (HEIs). Employing social learning theories, this opinion piece aims to explore generative AI as a stakeholder in learning. By weaving in social constructivist and learning theories, this opinion paper aims to uncover the capacity of generative AI to facilitate and enhance the learning process. Central to this opinion piece proposition is cultivating a learning community that leverages AI's potential as a new learning stakeholder. This opinion piece aims to contribute to ongoing discussions in the field of learning development by offering a fresh outlook on how AI can be an asset in knowledge co-creation and collaborative learning. The paper does this in the following ways: (1) highlights how generative AI can effectively contribute to learning and knowledge co-creation, and (2) provides some guidance for integrating generative AI in collaborative learning.},
}

